<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.24">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Chao Ma">
<meta name="dcterms.date" content="2026-01-22">

<title>Goodfellow Deep Learning — Chapter 20: Deep Generative Models – ∇ ickma.dev</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../favicon.svg" rel="icon" type="image/svg+xml">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dc55a5b9e770e841cd82e46aadbfb9b0.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-5b4ad623e5705c0698d39aec6f10cf02.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-PK5N5KWZBF"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-PK5N5KWZBF', { 'anonymize_ip': true});
</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../index.html" class="navbar-brand navbar-brand-logo">
    </a>
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">∇ ickma.dev</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-deep-learning" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Deep Learning</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-deep-learning">    
        <li class="dropdown-header">Papers in Deep Learning</li>
        <li>
    <a class="dropdown-item" href="../ML/papers/index.html">
 <span class="dropdown-text">Overview</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/papers/attention-origin-transformer.html">
 <span class="dropdown-text">Attention: The Origin of Transformer</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/papers/batch-normalization.html">
 <span class="dropdown-text">Batch Normalization</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/papers/lora.html">
 <span class="dropdown-text">LoRA: Low-Rank Adaptation</span></a>
  </li>  
        <li><hr class="dropdown-divider"></li>
        <li>
    <a class="dropdown-item" href="../ML/deep-learning-book.html">
 <span class="dropdown-text">Goodfellow Deep Learning Book (Overview)</span></a>
  </li>  
        <li><hr class="dropdown-divider"></li>
        <li>
    <a class="dropdown-item" href="../ML/xor-deep-learning.html">
 <span class="dropdown-text">Chapter 6.1: XOR Problem</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/likelihood-loss-functions.html">
 <span class="dropdown-text">Chapter 6.2: Loss Functions</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/activation-functions.html">
 <span class="dropdown-text">Chapter 6.3: Activation Functions</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/architecture-design.html">
 <span class="dropdown-text">Chapter 6.4: Architecture Design</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/backpropagation.html">
 <span class="dropdown-text">Chapter 6.5: Back-Propagation</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/hessian-prerequisites.html">
 <span class="dropdown-text">Chapter 7 Prerequisites: Hessian Matrix</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/l2-regularization.html">
 <span class="dropdown-text">Chapter 7.1.1: L2 Regularization</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/l1-regularization.html">
 <span class="dropdown-text">Chapter 7.1.2: L1 Regularization</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/constrained-optimization-regularization.html">
 <span class="dropdown-text">Chapter 7.2: Constrained Optimization</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/regularization-underconstrained.html">
 <span class="dropdown-text">Chapter 7.3: Under-Constrained Problems</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/dataset-augmentation.html">
 <span class="dropdown-text">Chapter 7.4: Dataset Augmentation</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/noise-robustness.html">
 <span class="dropdown-text">Chapter 7.5: Noise Robustness</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/semi-supervised-learning.html">
 <span class="dropdown-text">Chapter 7.6: Semi-Supervised Learning</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/multi-task-learning.html">
 <span class="dropdown-text">Chapter 7.7: Multi-Task Learning</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/early-stopping.html">
 <span class="dropdown-text">Chapter 7.8: Early Stopping</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/parameter-tying-sharing.html">
 <span class="dropdown-text">Chapter 7.9: Parameter Tying &amp; Sharing</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/representation-sparsity.html">
 <span class="dropdown-text">Chapter 7.10: Sparse Representations</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/bagging-ensemble.html">
 <span class="dropdown-text">Chapter 7.11: Bagging &amp; Ensemble Methods</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/dropout.html">
 <span class="dropdown-text">Chapter 7.12: Dropout</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/adversarial-training.html">
 <span class="dropdown-text">Chapter 7.13: Adversarial Training</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/tangent-prop-manifold.html">
 <span class="dropdown-text">Chapter 7.14: Tangent Prop &amp; Manifolds</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/learning-vs-optimization.html">
 <span class="dropdown-text">Chapter 8.1: Learning vs Optimization</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/optimization-challenges.html">
 <span class="dropdown-text">Chapter 8.2: Optimization Challenges</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/basic-optimization-algorithms.html">
 <span class="dropdown-text">Chapter 8.3: Basic Algorithms</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/parameter-initialization.html">
 <span class="dropdown-text">Chapter 8.4: Parameter Initialization</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/adaptive-learning-rates.html">
 <span class="dropdown-text">Chapter 8.5: Adaptive Learning Rates</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/second-order-methods.html">
 <span class="dropdown-text">Chapter 8.6: Second-Order Methods</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/optimization-strategies.html">
 <span class="dropdown-text">Chapter 8.7: Optimization Strategies</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/convolution-computation.html">
 <span class="dropdown-text">Chapter 9.1: Convolution Computation</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/cnn-motivation.html">
 <span class="dropdown-text">Chapter 9.2: CNN Motivation</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/cnn-pooling.html">
 <span class="dropdown-text">Chapter 9.3: Pooling</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/cnn-infinitely-strong-prior.html">
 <span class="dropdown-text">Chapter 9.4: Infinitely Strong Prior</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/convolutional-functions.html">
 <span class="dropdown-text">Chapter 9.5: Convolutional Functions</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/cnn-structured-outputs.html">
 <span class="dropdown-text">Chapter 9.6: Structured Outputs</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/cnn-data-types.html">
 <span class="dropdown-text">Chapter 9.7: Data Types</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/cnn-efficient-convolution.html">
 <span class="dropdown-text">Chapter 9.8: Efficient Convolution</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/cnn-unsupervised-learning.html">
 <span class="dropdown-text">Chapter 9.9: Unsupervised Feature Learning</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/cnn-neuroscience.html">
 <span class="dropdown-text">Chapter 9.10: Neuroscientific Basis</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/rnn-unfold-computation-graph.html">
 <span class="dropdown-text">Chapter 10.1: Unfold Computation Graph</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/rnn-recurrent-neural-networks.html">
 <span class="dropdown-text">Chapter 10.2: Recurrent Neural Networks</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/rnn-bidirectional.html">
 <span class="dropdown-text">Chapter 10.3: Bidirectional RNN</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/rnn-encoder-decoder.html">
 <span class="dropdown-text">Chapter 10.4: Encoder-Decoder Seq2Seq</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/rnn-deep.html">
 <span class="dropdown-text">Chapter 10.5: Deep RNN</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/rnn-recursive.html">
 <span class="dropdown-text">Chapter 10.6: Recursive Neural Network</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/rnn-long-term-dependency.html">
 <span class="dropdown-text">Chapter 10.7: Long-Term Dependencies</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/rnn-echo-state.html">
 <span class="dropdown-text">Chapter 10.8: Echo State Networks</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/rnn-leaky-unit.html">
 <span class="dropdown-text">Chapter 10.9: Leaky Units</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/rnn-lstm-gru.html">
 <span class="dropdown-text">Chapter 10.10: LSTM and GRU</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/rnn-optimize-long-term.html">
 <span class="dropdown-text">Chapter 10.11: Optimizing Long-Term Dependencies</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/rnn-explicit-memory.html">
 <span class="dropdown-text">Chapter 10.12: Explicit Memory</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/practical-methodology.html">
 <span class="dropdown-text">Chapter 11: Practical Methodology</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/large-scale-deep-learning.html">
 <span class="dropdown-text">Chapter 12.1: Large-Scale Deep Learning</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/image-preprocessing-normalization.html">
 <span class="dropdown-text">Chapter 12.2: Image Preprocessing and Normalization</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/automatic-speech-recognition.html">
 <span class="dropdown-text">Chapter 12.3: Automatic Speech Recognition</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/nlp-applications.html">
 <span class="dropdown-text">Chapter 12.4: NLP Applications</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/other-applications.html">
 <span class="dropdown-text">Chapter 12.5: Other Applications</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/linear-factor-models.html">
 <span class="dropdown-text">Chapter 13: Linear Factor Models</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/autoencoders.html">
 <span class="dropdown-text">Chapter 14: Autoencoders</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/representation-learning.html">
 <span class="dropdown-text">Chapter 15: Representation Learning</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/structured-probabilistic-models.html">
 <span class="dropdown-text">Chapter 16: Structured Probabilistic Models</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/monte-carlo-methods.html">
 <span class="dropdown-text">Chapter 17: Monte Carlo Methods</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/confronting-partition-function.html">
 <span class="dropdown-text">Chapter 18: Confronting the Partition Function</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/approximate-inference.html">
 <span class="dropdown-text">Chapter 19: Approximate Inference</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/deep-generative-models.html">
 <span class="dropdown-text">Chapter 20: Deep Generative Models</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-linear-algebra" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Linear Algebra</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-linear-algebra">    
        <li class="dropdown-header">Reflections &amp; Synthesis</li>
        <li>
    <a class="dropdown-item" href="../Math/reflections/mit1806-invertibility-connections.html">
 <span class="dropdown-text">Invertibility Connections</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Math/reflections/taylor-euler-fourier.html">
 <span class="dropdown-text">Taylor, Euler, and Fourier</span></a>
  </li>  
        <li><hr class="dropdown-divider"></li>
        <li class="dropdown-header">MIT 18.06SC Linear Algebra</li>
        <li>
    <a class="dropdown-item" href="../Math/MIT18.06/mit1806-lecture1-geometry.html">
 <span class="dropdown-text">Lecture 1: Geometry</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Math/MIT18.06/mit1806-lecture2-elimination.html">
 <span class="dropdown-text">Lecture 2: Elimination</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Math/MIT18.06/mit1806-lecture3-multiplication.html">
 <span class="dropdown-text">Lecture 3: Multiplication</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Math/MIT18.06/mit1806-lecture4-lu-decomposition.html">
 <span class="dropdown-text">Lecture 4: LU Decomposition</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Math/MIT18.06/mit1806-lecture5-permutations.html">
 <span class="dropdown-text">Lecture 5.1: Permutations</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Math/MIT18.06/mit1806-lecture5-2-transpose.html">
 <span class="dropdown-text">Lecture 5.2: Transpose</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Math/MIT18.06/mit1806-lecture5-3-spaces.html">
 <span class="dropdown-text">Lecture 5.3: Spaces</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Math/MIT18.06/mit1806-lecture6-column-null-space.html">
 <span class="dropdown-text">Lecture 6: Column &amp; Null Space</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Math/MIT18.06/mit1806-lecture7-solving-ax-0.html">
 <span class="dropdown-text">Lecture 7: Solving Ax=0</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Math/MIT18.06/mit1806-lecture8-solving-ax-b.html">
 <span class="dropdown-text">Lecture 8: Solving Ax=b</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Math/MIT18.06/mit1806-lecture9-independence-basis-dimension.html">
 <span class="dropdown-text">Lecture 9: Independence, Basis, Dimension</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Math/MIT18.06/mit1806-lecture10-four-subspaces.html">
 <span class="dropdown-text">Lecture 10: Four Fundamental Subspaces</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Math/MIT18.06/mit1806-lecture11-matrix-spaces.html">
 <span class="dropdown-text">Lecture 11: Matrix Spaces</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Math/MIT18.06/mit1806-lecture12-graphs-networks.html">
 <span class="dropdown-text">Lecture 12: Graphs and Networks</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Math/MIT18.06/mit1806-lecture13-quiz-review.html">
 <span class="dropdown-text">Lecture 13: Quiz 1 Review</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Math/MIT18.06/mit1806-lecture14-orthogonality.html">
 <span class="dropdown-text">Lecture 14: Orthogonality</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Math/MIT18.06/mit1806-lecture15-projections.html">
 <span class="dropdown-text">Lecture 15: Projections</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Math/MIT18.06/mit1806-lecture16-least-squares.html">
 <span class="dropdown-text">Lecture 16: Least Squares</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Math/MIT18.06/mit1806-lecture17-gram-schmidt.html">
 <span class="dropdown-text">Lecture 17: Gram-Schmidt</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Math/MIT18.06/mit1806-lecture18-determinants.html">
 <span class="dropdown-text">Lecture 18: Determinants</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Math/MIT18.06/mit1806-lecture19-determinant-formulas.html">
 <span class="dropdown-text">Lecture 19: Determinant Formulas</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Math/MIT18.06/mit1806-lecture20-cramers-rule.html">
 <span class="dropdown-text">Lecture 20: Inverse &amp; Volume</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Math/MIT18.06/mit1806-lecture21-eigenvalues-eigenvectors.html">
 <span class="dropdown-text">Lecture 21: Eigenvalues &amp; Eigenvectors</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Math/MIT18.06/mit1806-lecture22-diagonalization-powers.html">
 <span class="dropdown-text">Lecture 22: Diagonalization &amp; Powers</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Math/MIT18.06/mit1806-lecture23-differential-equations.html">
 <span class="dropdown-text">Lecture 23: Differential Equations</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Math/MIT18.06/mit1806-lecture24-markov-fourier.html">
 <span class="dropdown-text">Lecture 24: Markov &amp; Fourier</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Math/MIT18.06/mit1806-lecture25-symmetric-positive-definite.html">
 <span class="dropdown-text">Lecture 25: Symmetric &amp; Positive Definite</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Math/MIT18.06/mit1806-lecture26-complex-matrices-fft.html">
 <span class="dropdown-text">Lecture 26: Complex Matrices &amp; FFT</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Math/MIT18.06/mit1806-lecture27-positive-definite-minima.html">
 <span class="dropdown-text">Lecture 27: Positive Definite &amp; Minima</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Math/MIT18.06/mit1806-lecture28-similar-matrices-jordan.html">
 <span class="dropdown-text">Lecture 28: Similar Matrices &amp; Jordan Form</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Math/MIT18.06/mit1806-lecture29-svd.html">
 <span class="dropdown-text">Lecture 29: Singular Value Decomposition</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Math/MIT18.06/mit1806-lecture30-linear-transformations.html">
 <span class="dropdown-text">Lecture 30: Linear Transformations</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Math/MIT18.06/mit1806-lecture31-change-of-basis.html">
 <span class="dropdown-text">Lecture 31: Change of Basis</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Math/MIT18.06/mit1806-lecture33-left-right-inverse.html">
 <span class="dropdown-text">Lecture 33: Left &amp; Right Inverse</span></a>
  </li>  
        <li><hr class="dropdown-divider"></li>
        <li class="dropdown-header">MIT 18.065: Linear Algebra Applications</li>
        <li>
    <a class="dropdown-item" href="../Math/MIT18.065/mit18065-lecture1-column-space.html">
 <span class="dropdown-text">Lecture 1: Column Space</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Math/MIT18.065/mit18065-lecture2-multiplying-factoring.html">
 <span class="dropdown-text">Lecture 2: Multiplying and Factoring Matrices</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Math/MIT18.065/mit18065-lecture3-orthonormal-columns.html">
 <span class="dropdown-text">Lecture 3: Orthonormal Columns</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Math/MIT18.065/mit18065-lecture4-eigenvalues-eigenvectors.html">
 <span class="dropdown-text">Lecture 4: Eigenvalues and Eigenvectors</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Math/MIT18.065/mit18065-lecture5-positive-definite.html">
 <span class="dropdown-text">Lecture 5: Positive Definite Matrices</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Math/MIT18.065/mit18065-lecture6-svd.html">
 <span class="dropdown-text">Lecture 6: Singular Value Decomposition</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Math/MIT18.065/mit18065-lecture7-eckart-young.html">
 <span class="dropdown-text">Lecture 7: Eckart-Young Theorem</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Math/MIT18.065/mit18065-lecture8-norms.html">
 <span class="dropdown-text">Lecture 8: Norms</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Math/MIT18.065/mit18065-lecture9-least-squares.html">
 <span class="dropdown-text">Lecture 9: Least Squares</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Math/MIT18.065/mit18065-lecture10-axb-difficulties.html">
 <span class="dropdown-text">Lecture 10: Survey of Ax=b Difficulties</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Math/MIT18.065/lecture-11-minimize-norm-subject-to-constraint.html">
 <span class="dropdown-text">Lecture 11: Minimize Norm subject to Constraint</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Math/MIT18.065/mit18065-lecture12-eigenvalue-algorithms.html">
 <span class="dropdown-text">Lecture 12: Computing Eigenvalues</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Math/MIT18.065/mit18065-lecture13-randomized-matrix-multiplication.html">
 <span class="dropdown-text">Lecture 13: Randomized Matrix Multiplication</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Math/MIT18.065/mit18065-lecture14-low-rank-changes-inverse.html">
 <span class="dropdown-text">Lecture 14: Low Rank Changes</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Math/MIT18.065/mit18065-lecture15-matrix-derivatives.html">
 <span class="dropdown-text">Lecture 15: Matrix Derivatives</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Math/MIT18.065/mit18065-lecture16-derivative-inverse-singular-values.html">
 <span class="dropdown-text">Lecture 16: Derivative of Inverse and Singular Values</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Math/MIT18.065/mit18065-lecture17-rapidly-decreasing-singular-values.html">
 <span class="dropdown-text">Lecture 17: Rapidly Decreasing Singular Values</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Math/MIT18.065/mit18065-lecture18-counting-parameters-svd-lu-qr-saddle-points.html">
 <span class="dropdown-text">Lecture 18: Counting Parameters in SVD, LU, QR, and Saddle Points</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-calculus" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Calculus</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-calculus">    
        <li>
    <a class="dropdown-item" href="../Math/Calculus/index.html">
 <span class="dropdown-text">Overview</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Math/Calculus/max-min-second-derivative.html">
 <span class="dropdown-text">Gilbert Strang’s Calculus: Max, Min, and Second Derivative</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Math/Calculus/big-picture-derivatives.html">
 <span class="dropdown-text">Gilbert Strang’s Calculus: Big Picture on Derivatives</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Math/Calculus/highlights-of-calculus.html">
 <span class="dropdown-text">Gilbert Strang’s Calculus: Highlights</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-numerical-optimization" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Numerical Optimization</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-numerical-optimization">    
        <li>
    <a class="dropdown-item" href="../Math/EE364A/lectures.html">
 <span class="dropdown-text">Overview</span></a>
  </li>  
        <li class="dropdown-header">Stanford EE 364A: Convex Optimization</li>
        <li>
    <a class="dropdown-item" href="../Math/EE364A/ee364a-lecture1-intro.html">
 <span class="dropdown-text">Lecture 1: Introduction</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Math/EE364A/ee364a-lecture2-math-foundations.html">
 <span class="dropdown-text">Lecture 2: Convex Sets</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Math/EE364A/ee364a-lecture3-convex-functions.html">
 <span class="dropdown-text">Lecture 3: Convex Functions</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Math/EE364A/ee364a-lecture4-part1-operations-preserving-convexity.html">
 <span class="dropdown-text">Lecture 4.1: Operations Preserving Convexity</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Math/EE364A/ee364a-lecture4-part2-conjugate-quasiconvex.html">
 <span class="dropdown-text">Lecture 4.2: Conjugate &amp; Quasiconvex Functions</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Math/EE364A/ee364a-lecture5-part1-log-concave-convex.html">
 <span class="dropdown-text">Lecture 5.1: Log-Concave &amp; Log-Convex</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Math/EE364A/ee364a-lecture5-part2-monotonicity.html">
 <span class="dropdown-text">Lecture 5.2: Monotonicity</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Math/EE364A/ee364a-lecture6-optimization-problems.html">
 <span class="dropdown-text">Chapter 4.1: Optimization Problems</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Math/EE364A/ee364a-lecture7-convex-optimization.html">
 <span class="dropdown-text">Chapter 4.2: Convex Optimization</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Math/EE364A/ee364a-lecture8-linear-optimization.html">
 <span class="dropdown-text">Chapter 4.3: Linear Optimization</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Math/EE364A/ee364a-lecture9-quadratic-optimization.html">
 <span class="dropdown-text">Chapter 4.4: Quadratic Optimization</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Math/EE364A/ee364a-chapter4-5-geometric-programming.html">
 <span class="dropdown-text">Chapter 4.5: Geometric Programming</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Math/EE364A/ee364a-chapter4-6-generalized-inequality-constraints.html">
 <span class="dropdown-text">Chapter 4.6: Generalized Inequality Constraints</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Math/EE364A/ee364a-chapter4-7-vector-optimization.html">
 <span class="dropdown-text">Chapter 4.7: Vector Optimization</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Math/EE364A/ee364a-chapter5-1-lagrange-dual-function.html">
 <span class="dropdown-text">Chapter 5.1: The Lagrange Dual Function</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-theory-to-repro" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Theory-to-Repro</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-theory-to-repro">    
        <li>
    <a class="dropdown-item" href="../Theory-to-Repro/index.html">
 <span class="dropdown-text">Overview</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Theory-to-Repro/linear-regression-three-ways.html">
 <span class="dropdown-text">Linear Regression via Three Solvers</span></a>
  </li>  
        <li><hr class="dropdown-divider"></li>
        <li>
    <a class="dropdown-item" href="../ML/k_means_clustering.html">
 <span class="dropdown-text">K-Means Clustering</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/logistic_regression.html">
 <span class="dropdown-text">Logistic Regression</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../ML/axis.html">
 <span class="dropdown-text">Axis Operations</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Algorithm/dp_regex.html">
 <span class="dropdown-text">DP Regex</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://github.com/ickma2311/ickma2311.github.io/discussions"> 
<span class="menu-text">Feedback</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#boltzmann-machines" id="toc-boltzmann-machines" class="nav-link active" data-scroll-target="#boltzmann-machines">20.1 Boltzmann machines</a></li>
  <li><a href="#restricted-boltzmann-machines-rbms" id="toc-restricted-boltzmann-machines-rbms" class="nav-link" data-scroll-target="#restricted-boltzmann-machines-rbms">20.2 Restricted Boltzmann machines (RBMs)</a>
  <ul class="collapse">
  <li><a href="#conditional-distributions" id="toc-conditional-distributions" class="nav-link" data-scroll-target="#conditional-distributions">20.2.1 Conditional distributions</a></li>
  <li><a href="#training-rbms" id="toc-training-rbms" class="nav-link" data-scroll-target="#training-rbms">20.2.2 Training RBMs</a></li>
  </ul></li>
  <li><a href="#deep-belief-networks-dbns" id="toc-deep-belief-networks-dbns" class="nav-link" data-scroll-target="#deep-belief-networks-dbns">20.3 Deep belief networks (DBNs)</a></li>
  <li><a href="#deep-boltzmann-machines-dbms" id="toc-deep-boltzmann-machines-dbms" class="nav-link" data-scroll-target="#deep-boltzmann-machines-dbms">20.4 Deep Boltzmann machines (DBMs)</a>
  <ul class="collapse">
  <li><a href="#interesting-properties" id="toc-interesting-properties" class="nav-link" data-scroll-target="#interesting-properties">20.4.1 Interesting properties</a></li>
  <li><a href="#mean-field-inference" id="toc-mean-field-inference" class="nav-link" data-scroll-target="#mean-field-inference">20.4.2 Mean-field inference</a></li>
  <li><a href="#parameter-learning" id="toc-parameter-learning" class="nav-link" data-scroll-target="#parameter-learning">20.4.3 Parameter learning</a></li>
  <li><a href="#layer-wise-pretraining" id="toc-layer-wise-pretraining" class="nav-link" data-scroll-target="#layer-wise-pretraining">20.4.4 Layer-wise pretraining</a></li>
  <li><a href="#joint-training" id="toc-joint-training" class="nav-link" data-scroll-target="#joint-training">20.4.5 Joint training</a></li>
  </ul></li>
  <li><a href="#boltzmann-machines-for-real-valued-data" id="toc-boltzmann-machines-for-real-valued-data" class="nav-link" data-scroll-target="#boltzmann-machines-for-real-valued-data">20.5 Boltzmann machines for real-valued data</a>
  <ul class="collapse">
  <li><a href="#gaussianbernoulli-rbms" id="toc-gaussianbernoulli-rbms" class="nav-link" data-scroll-target="#gaussianbernoulli-rbms">20.5.1 Gaussian–Bernoulli RBMs</a></li>
  <li><a href="#conditional-covariance-models" id="toc-conditional-covariance-models" class="nav-link" data-scroll-target="#conditional-covariance-models">20.5.2 Conditional covariance models</a></li>
  </ul></li>
  <li><a href="#convolutional-boltzmann-machines" id="toc-convolutional-boltzmann-machines" class="nav-link" data-scroll-target="#convolutional-boltzmann-machines">20.6 Convolutional Boltzmann machines</a></li>
  <li><a href="#boltzmann-machines-for-structured-or-sequential-data" id="toc-boltzmann-machines-for-structured-or-sequential-data" class="nav-link" data-scroll-target="#boltzmann-machines-for-structured-or-sequential-data">20.7 Boltzmann machines for structured or sequential data</a></li>
  <li><a href="#other-boltzmann-machines" id="toc-other-boltzmann-machines" class="nav-link" data-scroll-target="#other-boltzmann-machines">20.8 Other Boltzmann machines</a></li>
  <li><a href="#back-propagation-through-random-operations" id="toc-back-propagation-through-random-operations" class="nav-link" data-scroll-target="#back-propagation-through-random-operations">20.9 Back-propagation through random operations</a>
  <ul class="collapse">
  <li><a href="#discrete-stochastic-operations" id="toc-discrete-stochastic-operations" class="nav-link" data-scroll-target="#discrete-stochastic-operations">20.9.1 Discrete stochastic operations</a></li>
  </ul></li>
  <li><a href="#directed-generative-networks" id="toc-directed-generative-networks" class="nav-link" data-scroll-target="#directed-generative-networks">20.10 Directed generative networks</a>
  <ul class="collapse">
  <li><a href="#sigmoid-belief-networks" id="toc-sigmoid-belief-networks" class="nav-link" data-scroll-target="#sigmoid-belief-networks">20.10.1 Sigmoid belief networks</a></li>
  <li><a href="#differentiable-generator-networks" id="toc-differentiable-generator-networks" class="nav-link" data-scroll-target="#differentiable-generator-networks">20.10.2 Differentiable generator networks</a></li>
  <li><a href="#variational-autoencoders-vaes" id="toc-variational-autoencoders-vaes" class="nav-link" data-scroll-target="#variational-autoencoders-vaes">20.10.3 Variational autoencoders (VAEs)</a></li>
  <li><a href="#generative-adversarial-networks-gans" id="toc-generative-adversarial-networks-gans" class="nav-link" data-scroll-target="#generative-adversarial-networks-gans">20.10.4 Generative adversarial networks (GANs)</a></li>
  <li><a href="#generative-moment-matching-networks-gmmns" id="toc-generative-moment-matching-networks-gmmns" class="nav-link" data-scroll-target="#generative-moment-matching-networks-gmmns">20.10.5 Generative moment matching networks (GMMNs)</a></li>
  <li><a href="#convolutional-generative-networks" id="toc-convolutional-generative-networks" class="nav-link" data-scroll-target="#convolutional-generative-networks">20.10.6 Convolutional generative networks</a></li>
  <li><a href="#auto-regressive-networks" id="toc-auto-regressive-networks" class="nav-link" data-scroll-target="#auto-regressive-networks">20.10.7 Auto-regressive networks</a></li>
  <li><a href="#linear-auto-regressive-networks" id="toc-linear-auto-regressive-networks" class="nav-link" data-scroll-target="#linear-auto-regressive-networks">20.10.8 Linear auto-regressive networks</a></li>
  <li><a href="#neural-auto-regressive-networks" id="toc-neural-auto-regressive-networks" class="nav-link" data-scroll-target="#neural-auto-regressive-networks">20.10.9 Neural auto-regressive networks</a></li>
  <li><a href="#nade" id="toc-nade" class="nav-link" data-scroll-target="#nade">20.10.10 NADE</a></li>
  </ul></li>
  <li><a href="#drawing-samples-from-autoencoders" id="toc-drawing-samples-from-autoencoders" class="nav-link" data-scroll-target="#drawing-samples-from-autoencoders">20.11 Drawing samples from autoencoders</a>
  <ul class="collapse">
  <li><a href="#associated-markov-chain" id="toc-associated-markov-chain" class="nav-link" data-scroll-target="#associated-markov-chain">20.11.1 Associated Markov chain</a></li>
  <li><a href="#clamping-and-conditional-sampling" id="toc-clamping-and-conditional-sampling" class="nav-link" data-scroll-target="#clamping-and-conditional-sampling">20.11.2 Clamping and conditional sampling</a></li>
  <li><a href="#walk-back-training" id="toc-walk-back-training" class="nav-link" data-scroll-target="#walk-back-training">20.11.3 Walk-back training</a></li>
  </ul></li>
  <li><a href="#generative-stochastic-networks-gsns" id="toc-generative-stochastic-networks-gsns" class="nav-link" data-scroll-target="#generative-stochastic-networks-gsns">20.12 Generative stochastic networks (GSNs)</a>
  <ul class="collapse">
  <li><a href="#discriminant-gsns" id="toc-discriminant-gsns" class="nav-link" data-scroll-target="#discriminant-gsns">20.12.1 Discriminant GSNs</a></li>
  </ul></li>
  <li><a href="#other-generation-schemes" id="toc-other-generation-schemes" class="nav-link" data-scroll-target="#other-generation-schemes">20.13 Other generation schemes</a></li>
  <li><a href="#evaluating-generative-models" id="toc-evaluating-generative-models" class="nav-link" data-scroll-target="#evaluating-generative-models">20.14 Evaluating generative models</a></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">20.15 Conclusion</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">Goodfellow Deep Learning — Chapter 20: Deep Generative Models</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
  <div class="quarto-categories">
    <div class="quarto-category">Deep Learning</div>
    <div class="quarto-category">Generative Models</div>
    <div class="quarto-category">Latent Variables</div>
    <div class="quarto-category">Approximate Inference</div>
  </div>
  </div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Chao Ma </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">January 22, 2026</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<p>Deep generative models describe probability distributions over many variables. Some models give an explicit density that can be evaluated; others only support operations that imply a distribution (such as sampling). Chapter 20 surveys the families that can be built from the tools of Chapters 16–19: graphical models, energy-based models, approximate inference, and stochastic optimization. The common thread is that <strong>exact inference is rarely tractable</strong>, so training relies on approximate objectives, clever factorization, or implicit learning signals.</p>
<p>Two complementary axes organize the landscape. First, <strong>explicit vs implicit density</strong>: energy-based models and autoregressive models define a normalized probability (or can estimate it), while adversarial or moment-matching models define a procedure that generates samples without an explicit likelihood. Second, <strong>directed vs undirected structure</strong>: directed models factorize via the chain rule, while undirected models encode dependencies symmetrically through energies. The chapter’s message is that every choice brings tradeoffs in tractability, sample quality, and optimization stability.</p>
<section id="boltzmann-machines" class="level2">
<h2 class="anchored" data-anchor-id="boltzmann-machines">20.1 Boltzmann machines</h2>
<p>Boltzmann machines are <strong>energy-based models</strong> for binary vectors. The model defines a probability mass function through an energy function: <span class="math display">\[
P(x)=\frac{\exp(-E(x))}{Z},
\]</span> where the partition function <span class="math inline">\(Z=\sum_x \exp(-E(x))\)</span> normalizes the distribution. For a binary vector <span class="math inline">\(x\in\{0,1\}^d\)</span>, a basic Boltzmann machine uses a quadratic energy <span class="math display">\[
E(x)=-x^\top Ux-b^\top x,
\]</span> with parameters <span class="math inline">\(U\)</span> and <span class="math inline">\(b\)</span>. This already defines a valid distribution, but it limits interactions to those expressible through a pairwise quadratic form.</p>
<p>The model becomes much more expressive when we introduce <strong>latent (hidden) units</strong>. Splitting the variables into visible <span class="math inline">\(v\)</span> and hidden <span class="math inline">\(h\)</span>, a general Boltzmann machine has energy <span class="math display">\[
E(v,h)=-v^\top Rv - v^\top Wh - h^\top Sh - b^\top v - c^\top h.
\]</span> With hidden units, the model can capture higher-order dependencies between visible variables and becomes a universal approximator of discrete distributions. The cost is that both the partition function and the posterior <span class="math inline">\(p(h\mid v)\)</span> are intractable in general, so exact learning and inference are not feasible.</p>
<p>Learning typically follows <strong>maximum likelihood</strong>, which yields gradients in terms of differences between statistics under the data and the model. The intractable expectations require approximations (e.g., MCMC), and training depends on techniques from Chapter 18. Intuitively, the model increases probability mass near data points by decreasing energy in those regions, while the partition function pushes back by raising energy elsewhere. This tug-of-war is the “positive phase vs negative phase” structure shared by many energy-based models.</p>
</section>
<section id="restricted-boltzmann-machines-rbms" class="level2">
<h2 class="anchored" data-anchor-id="restricted-boltzmann-machines-rbms">20.2 Restricted Boltzmann machines (RBMs)</h2>
<p>Restricted Boltzmann machines simplify the structure by making the graph <strong>bipartite</strong>: visible units connect only to hidden units, and there are no lateral connections within a layer. This restriction creates a useful conditional independence structure while retaining expressive power.</p>
<p>An RBM defines the joint distribution as <span class="math display">\[
P(v,h)=\frac{1}{Z}\exp\{-E(v,h)\},
\]</span> with energy <span class="math display">\[
E(v,h)=-b^\top v - c^\top h - v^\top Wh.
\]</span> Because of the bipartite graph, the conditional distributions factorize: <span class="math display">\[
P(h\mid v)=\prod_i P(h_i\mid v),\quad P(v\mid h)=\prod_j P(v_j\mid h).
\]</span> For binary units, each conditional is a sigmoid: <span class="math display">\[
P(h_i=1\mid v)=\sigma(c_i + W_i^\top v),\quad P(v_j=1\mid h)=\sigma(b_j + W_j h).
\]</span> This makes <strong>inference and sampling</strong> efficient via block Gibbs updates.</p>
<section id="conditional-distributions" class="level3">
<h3 class="anchored" data-anchor-id="conditional-distributions">20.2.1 Conditional distributions</h3>
<p>The key advantage of an RBM is that although <span class="math inline">\(P(v)\)</span> is intractable (because <span class="math inline">\(Z\)</span> is intractable), both conditionals are easy to compute and sample from. This enables a practical MCMC loop that alternates between sampling <span class="math inline">\(h\sim P(h\mid v)\)</span> and <span class="math inline">\(v\sim P(v\mid h)\)</span>.</p>
</section>
<section id="training-rbms" class="level3">
<h3 class="anchored" data-anchor-id="training-rbms">20.2.2 Training RBMs</h3>
<p>RBMs are trained by maximum likelihood using approximate gradients. Because block Gibbs updates are efficient, standard methods from Chapter 18 are particularly convenient here: - <strong>Contrastive divergence (CD)</strong> - <strong>Stochastic maximum likelihood / persistent CD (SML/PCD)</strong> - <strong>Ratio matching</strong></p>
<p>The gradient of the log-likelihood involves a <strong>data term</strong> (expectation under <span class="math inline">\(P(h\mid v)\)</span> for data <span class="math inline">\(v\)</span>) and a <strong>model term</strong> (expectation under the model distribution). The latter is approximated using the Markov chain. RBMs are among the most tractable undirected models used in deep learning because their conditionals are simple and their MCMC transitions mix relatively well compared to more general Boltzmann machines. CD uses short chains initialized at data to approximate the negative phase, which is biased but often effective; PCD keeps a persistent chain to reduce bias at the cost of additional state. In practice, training stability depends on learning rates, regularization, and ensuring the chain does not drift too far from the data manifold.</p>
</section>
</section>
<section id="deep-belief-networks-dbns" class="level2">
<h2 class="anchored" data-anchor-id="deep-belief-networks-dbns">20.3 Deep belief networks (DBNs)</h2>
<p>Deep belief networks were one of the first successful deep probabilistic models and played a major role in the 2006 deep learning renaissance. A DBN stacks multiple layers of latent variables. It is <strong>hybrid</strong>: - The top two layers form an undirected model (an RBM). - Lower layers are directed generative connections.</p>
<p>DBNs are trained <strong>greedily</strong> by stacking RBMs: each layer learns to model the hidden representation of the layer below. This provides a strong initialization for deep architectures that were otherwise difficult to optimize. After greedy pretraining, the model can be fine-tuned with approximate likelihood or a recognition network. The greedy scheme can be understood as improving a variational lower bound on the data log-likelihood layer by layer. Even when the full model is not optimized end-to-end, the resulting latent hierarchy captures increasingly abstract features, which historically made DBNs useful for transfer and semi-supervised learning.</p>
</section>
<section id="deep-boltzmann-machines-dbms" class="level2">
<h2 class="anchored" data-anchor-id="deep-boltzmann-machines-dbms">20.4 Deep Boltzmann machines (DBMs)</h2>
<p>A DBM is a fully <strong>undirected</strong> model with multiple hidden layers. Like RBMs, it has a bipartite structure <strong>between adjacent layers</strong>, so units within a layer are conditionally independent given the neighboring layers. This yields a structured yet deep energy-based model.</p>
<p>DBMs differ from DBNs in that <strong>all layers are undirected</strong>, and the posterior is closer to a factorial form, which enables richer variational approximations. The tradeoff is harder learning: both the partition function and the posterior are intractable.</p>
<section id="interesting-properties" class="level3">
<h3 class="anchored" data-anchor-id="interesting-properties">20.4.1 Interesting properties</h3>
<p>Compared to DBNs, DBMs have posterior distributions that are easier to approximate with mean-field methods, even though their graphical structure is deeper. This leads to more accurate approximate inference in some settings.</p>
</section>
<section id="mean-field-inference" class="level3">
<h3 class="anchored" data-anchor-id="mean-field-inference">20.4.2 Mean-field inference</h3>
<p>Mean-field inference approximates <span class="math inline">\(p(h\mid v)\)</span> with a factorized distribution <span class="math inline">\(Q(h\mid v)=\prod_i q_i(h_i\mid v)\)</span>. The updates follow fixed-point equations derived from minimizing KL divergence. Because each layer is conditionally independent given its neighbors, the update for a unit depends only on expectations from adjacent layers, leading to iterative message passing.</p>
</section>
<section id="parameter-learning" class="level3">
<h3 class="anchored" data-anchor-id="parameter-learning">20.4.3 Parameter learning</h3>
<p>Learning combines two approximations: - <strong>Stochastic maximum likelihood</strong> to handle the intractable partition function. - <strong>Variational inference</strong> to handle the intractable posterior.</p>
<p>The variational distribution provides an approximate “positive phase,” while MCMC provides the “negative phase.” DBMs are conceptually appealing because they define a single coherent undirected distribution over all layers, but in practice they are sensitive to initialization and require careful tuning to avoid poor local optima.</p>
</section>
<section id="layer-wise-pretraining" class="level3">
<h3 class="anchored" data-anchor-id="layer-wise-pretraining">20.4.4 Layer-wise pretraining</h3>
<p>Training a DBM from random initialization often fails: it can collapse to an RBM-like solution where upper layers are unused. Greedy layer-wise pretraining (via RBMs) helps initialize each layer with meaningful structure, preventing the model from ignoring deeper layers.</p>
</section>
<section id="joint-training" class="level3">
<h3 class="anchored" data-anchor-id="joint-training">20.4.5 Joint training</h3>
<p>Greedy pretraining has drawbacks (slow feedback, difficult hyperparameter tuning). Joint training attempts to optimize all layers together, often using a recognition network to initialize variational inference. This improves end-to-end learning but is more complex to implement.</p>
</section>
</section>
<section id="boltzmann-machines-for-real-valued-data" class="level2">
<h2 class="anchored" data-anchor-id="boltzmann-machines-for-real-valued-data">20.5 Boltzmann machines for real-valued data</h2>
<p>Many real-world data types are continuous. There are two strategies: 1. Treat a real value in <span class="math inline">\([0,1]\)</span> as the mean of a Bernoulli (approximation). 2. Use <strong>Gaussian visible units</strong>, yielding Gaussian–Bernoulli RBMs.</p>
<p>Gaussian–Bernoulli RBMs replace the binary visible distribution with a Gaussian conditional. The energy function is adjusted accordingly, leading to linear Gaussian conditionals for visibles and logistic conditionals for hiddens. This supports modeling real-valued data such as images and audio. When using Gaussian visibles, the variance can be fixed or learned. Fixing variance simplifies training but may underfit; learning variance increases flexibility but can destabilize optimization without appropriate constraints or priors.</p>
<section id="gaussianbernoulli-rbms" class="level3">
<h3 class="anchored" data-anchor-id="gaussianbernoulli-rbms">20.5.1 Gaussian–Bernoulli RBMs</h3>
<p>A Gaussian–Bernoulli RBM keeps hidden units binary but makes visible units Gaussian. This allows real-valued observations while preserving efficient conditional sampling.</p>
</section>
<section id="conditional-covariance-models" class="level3">
<h3 class="anchored" data-anchor-id="conditional-covariance-models">20.5.2 Conditional covariance models</h3>
<p>RBMs can be extended to model not only means but also <strong>conditional covariance structure</strong>. These models capture second-order dependencies in real-valued data by introducing interactions that change variance as a function of the hidden state.</p>
</section>
</section>
<section id="convolutional-boltzmann-machines" class="level2">
<h2 class="anchored" data-anchor-id="convolutional-boltzmann-machines">20.6 Convolutional Boltzmann machines</h2>
<p>Convolutional structure introduces <strong>weight sharing and locality</strong>, making the model more suitable for images. Convolutional RBMs learn filters that are applied across spatial locations, producing hidden feature maps. Pooling or subsampling operations can be used to gain translation invariance and reduce spatial resolution while maintaining probabilistic semantics. These models connect classical probabilistic learning with modern convolutional architectures: feature maps act like latent detectors, and shared filters encourage the model to reuse visual primitives. Training still relies on CD or PCD, but the convolutional structure reduces parameter count and tends to improve sample quality for image-like data.</p>
</section>
<section id="boltzmann-machines-for-structured-or-sequential-data" class="level2">
<h2 class="anchored" data-anchor-id="boltzmann-machines-for-structured-or-sequential-data">20.7 Boltzmann machines for structured or sequential data</h2>
<p>Boltzmann machines can be adapted to sequences or structured outputs by conditioning on context or introducing temporal connections. For example, conditional RBMs incorporate past observations, and structured RBMs can encode constraints that tie together multiple variables across time or spatial layouts. Temporal extensions treat each time step as a visible layer connected to hidden variables that summarize history. This makes the model suitable for motion capture or sequence prediction, where the latent state captures dynamics while the visible units represent observations.</p>
</section>
<section id="other-boltzmann-machines" class="level2">
<h2 class="anchored" data-anchor-id="other-boltzmann-machines">20.8 Other Boltzmann machines</h2>
<p>The Boltzmann framework supports many variants: different variable types, structured connectivity, and specialized energies. These variants aim to balance expressivity with tractable inference or efficient sampling.</p>
</section>
<section id="back-propagation-through-random-operations" class="level2">
<h2 class="anchored" data-anchor-id="back-propagation-through-random-operations">20.9 Back-propagation through random operations</h2>
<p>Training generative models often requires gradients through <strong>stochastic nodes</strong>. When outputs depend on random sampling, naive back-propagation fails. Two main ideas appear:</p>
<ul>
<li><strong>Reparameterization-style gradients</strong>: express a random variable as a deterministic function of noise, enabling gradients to pass through the deterministic transformation.</li>
<li><strong>Score-function estimators</strong> (likelihood-ratio / REINFORCE): move the gradient inside the expectation using <span class="math display">\[
\nabla_\theta \mathbb{E}_{x\sim p_\theta}[f(x)] = \mathbb{E}_{x\sim p_\theta}[f(x)\nabla_\theta \log p_\theta(x)].
\]</span></li>
</ul>
<section id="discrete-stochastic-operations" class="level3">
<h3 class="anchored" data-anchor-id="discrete-stochastic-operations">20.9.1 Discrete stochastic operations</h3>
<p>Discrete random variables make reparameterization difficult, so score-function estimators are common. These estimators are unbiased but can have high variance, motivating variance-reduction tricks such as baselines or control variates. Reparameterization is especially effective for continuous latent variables: sampling <span class="math inline">\(z=\mu+\sigma\odot\epsilon\)</span> with <span class="math inline">\(\epsilon\sim\mathcal{N}(0,I)\)</span> turns a stochastic node into a differentiable function of noise, which dramatically reduces gradient variance compared to score-function estimators.</p>
</section>
</section>
<section id="directed-generative-networks" class="level2">
<h2 class="anchored" data-anchor-id="directed-generative-networks">20.10 Directed generative networks</h2>
<p>Directed models represent joint distributions via the chain rule and conditional distributions defined by neural networks. These models became prominent in deep learning after 2013, complementing undirected approaches like RBMs.</p>
<section id="sigmoid-belief-networks" class="level3">
<h3 class="anchored" data-anchor-id="sigmoid-belief-networks">20.10.1 Sigmoid belief networks</h3>
<p>A sigmoid belief network (SBN) is a directed graphical model with binary units. Each unit’s activation is determined by a sigmoid of weighted inputs from its parents. This is a probabilistic analogue of a multilayer perceptron, but with latent randomness.</p>
</section>
<section id="differentiable-generator-networks" class="level3">
<h3 class="anchored" data-anchor-id="differentiable-generator-networks">20.10.2 Differentiable generator networks</h3>
<p>A general strategy for generative modeling is to map latent variables <span class="math inline">\(z\)</span> to data space using a differentiable function <span class="math inline">\(g(z;\theta)\)</span>. Sampling is easy: draw <span class="math inline">\(z\sim p(z)\)</span> and compute <span class="math inline">\(x=g(z;\theta)\)</span>. The challenge is learning <span class="math inline">\(\theta\)</span>, which depends on the training criterion (ELBO, adversarial loss, moment matching, etc.). Depending on the loss, the same generator can behave very differently. Maximum-likelihood or ELBO objectives emphasize coverage of the data distribution (discouraging missing modes), while adversarial or moment-matching objectives may emphasize sharp, realistic samples even if some modes are dropped. This explains why different families are favored for different goals.</p>
</section>
<section id="variational-autoencoders-vaes" class="level3">
<h3 class="anchored" data-anchor-id="variational-autoencoders-vaes">20.10.3 Variational autoencoders (VAEs)</h3>
<p>A VAE combines a generator network with an <strong>inference network</strong> that approximates the posterior. Training maximizes the ELBO using reparameterization. The model defines <span class="math display">\[
p(z)p(x\mid z),
\]</span> and learns an encoder <span class="math inline">\(q(z\mid x)\)</span> for approximate inference. VAEs provide a principled likelihood-based model with efficient training. The ELBO decomposes into a reconstruction term and a KL regularizer: <span class="math display">\[
\mathbb{E}_{q(z\mid x)}[\log p(x\mid z)] - D_{\mathrm{KL}}(q(z\mid x)\|p(z)).
\]</span> This highlights the tradeoff between fidelity to data and keeping the approximate posterior close to the prior. Variants such as <span class="math inline">\(\beta\)</span>-VAE adjust this balance to encourage disentangled latents.</p>
</section>
<section id="generative-adversarial-networks-gans" class="level3">
<h3 class="anchored" data-anchor-id="generative-adversarial-networks-gans">20.10.4 Generative adversarial networks (GANs)</h3>
<p>GANs set up a two-player game between a generator and a discriminator. The generator tries to produce samples that fool the discriminator, while the discriminator learns to distinguish real from generated data. GANs avoid explicit likelihood evaluation and often produce sharp samples but can be unstable to train. The original GAN objective corresponds to minimizing the Jensen–Shannon divergence between model and data distributions. Instability issues like mode collapse motivate alternative losses (e.g., Wasserstein GAN) and regularization strategies that improve gradient behavior.</p>
</section>
<section id="generative-moment-matching-networks-gmmns" class="level3">
<h3 class="anchored" data-anchor-id="generative-moment-matching-networks-gmmns">20.10.5 Generative moment matching networks (GMMNs)</h3>
<p>GMMNs train a generator so that <strong>statistics (moments)</strong> of generated samples match those of real data. This is often done with kernel-based discrepancy measures (e.g., maximum mean discrepancy). No inference network or discriminator is required, but the choice of moments critically affects performance.</p>
</section>
<section id="convolutional-generative-networks" class="level3">
<h3 class="anchored" data-anchor-id="convolutional-generative-networks">20.10.6 Convolutional generative networks</h3>
<p>For images, generator networks benefit from convolutional structure and transpose convolutions. This leverages locality and parameter sharing, often improving sample quality and reducing parameter count.</p>
</section>
<section id="auto-regressive-networks" class="level3">
<h3 class="anchored" data-anchor-id="auto-regressive-networks">20.10.7 Auto-regressive networks</h3>
<p>Auto-regressive models factorize the joint distribution via the chain rule: <span class="math display">\[
P(x)=\prod_i P(x_i\mid x_{&lt;i}).
\]</span> They can achieve exact likelihoods but require sequential sampling. They contain <strong>no latent variables</strong>, relying instead on conditional distributions modeled by neural networks. Examples like PixelRNN and PixelCNN demonstrate how autoregressive factorization can yield state-of-the-art density estimation for images, at the cost of slow sampling because each pixel must be generated in sequence.</p>
</section>
<section id="linear-auto-regressive-networks" class="level3">
<h3 class="anchored" data-anchor-id="linear-auto-regressive-networks">20.10.8 Linear auto-regressive networks</h3>
<p>The simplest auto-regressive models use linear predictors (e.g., logistic regression for binary data). They are conceptually straightforward but may lack capacity for complex data distributions.</p>
</section>
<section id="neural-auto-regressive-networks" class="level3">
<h3 class="anchored" data-anchor-id="neural-auto-regressive-networks">20.10.9 Neural auto-regressive networks</h3>
<p>Neural auto-regressive networks use nonlinear hidden layers and parameter sharing to improve expressivity. This creates powerful density estimators with tractable likelihoods.</p>
</section>
<section id="nade" class="level3">
<h3 class="anchored" data-anchor-id="nade">20.10.10 NADE</h3>
<p>The Neural Auto-Regressive Density Estimator (NADE) introduces a specific parameter-sharing scheme that makes training efficient while retaining strong modeling power. NADE is widely used as a tractable alternative to RBMs for certain data types. NADE’s main appeal is that it provides <strong>exact log-likelihood</strong> and efficient training via maximum likelihood, avoiding MCMC. It can be seen as an autoregressive model with shared weights that reuse hidden activations across conditional distributions, making it a practical density estimator for moderate-dimensional data.</p>
</section>
</section>
<section id="drawing-samples-from-autoencoders" class="level2">
<h2 class="anchored" data-anchor-id="drawing-samples-from-autoencoders">20.11 Drawing samples from autoencoders</h2>
<p>Autoencoders can define implicit generative models by constructing a Markov chain. For denoising autoencoders, the transition consists of corrupting a sample and then denoising it. Repeating this process yields samples from an implicit distribution. These models blur the line between encoder-decoder representation learning and generative modeling: the decoder learns to map noisy points back to the data manifold, and the resulting chain can be interpreted as sampling from that manifold.</p>
<section id="associated-markov-chain" class="level3">
<h3 class="anchored" data-anchor-id="associated-markov-chain">20.11.1 Associated Markov chain</h3>
<p>A denoising autoencoder defines a transition kernel that alternates between corruption and reconstruction. Under suitable conditions, this Markov chain has a stationary distribution related to the data distribution.</p>
</section>
<section id="clamping-and-conditional-sampling" class="level3">
<h3 class="anchored" data-anchor-id="clamping-and-conditional-sampling">20.11.2 Clamping and conditional sampling</h3>
<p>By clamping some variables and running the chain on the rest, the model can perform conditional generation or inpainting.</p>
</section>
<section id="walk-back-training" class="level3">
<h3 class="anchored" data-anchor-id="walk-back-training">20.11.3 Walk-back training</h3>
<p>Walk-back training improves denoising autoencoders by training them on samples drawn from the model’s own Markov chain, reducing spurious modes and encouraging the model to “walk back” toward the data manifold.</p>
</section>
</section>
<section id="generative-stochastic-networks-gsns" class="level2">
<h2 class="anchored" data-anchor-id="generative-stochastic-networks-gsns">20.12 Generative stochastic networks (GSNs)</h2>
<p>GSNs generalize denoising autoencoders by defining a stochastic transition operator for a Markov chain. The model is trained so that the chain’s stationary distribution matches the data distribution. Unlike RBMs, GSNs do not require an explicit energy function or partition function. Viewed through a modern lens, GSNs relate to <strong>score matching</strong> and diffusion-style ideas: learning to denoise implicitly estimates the score (the gradient of log density), and repeated denoising steps form a sampler that moves toward high-density regions.</p>
<section id="discriminant-gsns" class="level3">
<h3 class="anchored" data-anchor-id="discriminant-gsns">20.12.1 Discriminant GSNs</h3>
<p>Discriminant GSNs incorporate supervised signals while maintaining a generative interpretation, enabling semi-supervised or structured prediction tasks.</p>
</section>
</section>
<section id="other-generation-schemes" class="level2">
<h2 class="anchored" data-anchor-id="other-generation-schemes">20.13 Other generation schemes</h2>
<p>The chapter also highlights alternative generative strategies that do not fit neatly into RBM, VAE, or GAN categories. The unifying theme is trading off <strong>tractability</strong>, <strong>sample quality</strong>, and <strong>training stability</strong> depending on the model family and objective.</p>
</section>
<section id="evaluating-generative-models" class="level2">
<h2 class="anchored" data-anchor-id="evaluating-generative-models">20.14 Evaluating generative models</h2>
<p>Evaluating generative models is subtle. Sometimes we can compute exact log-likelihoods; other times we only have stochastic estimates or lower bounds. Comparing models under different evaluation criteria can be misleading. The key is to be explicit about what is measured: - Exact log-likelihood vs.&nbsp;approximate estimates - Lower bounds vs.&nbsp;unbiased estimators - Sample quality vs.&nbsp;density quality</p>
<p>Evaluation should align with the intended use: density estimation, sampling quality, or downstream task performance. Common proxy metrics like the Inception Score or FID measure sample quality using pretrained classifiers, but they do not directly reflect likelihood. Recent work proposes precision/recall decompositions to characterize both fidelity and diversity, emphasizing that no single metric captures all desired properties.</p>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">20.15 Conclusion</h2>
<p>Deep generative modeling spans a wide family: energy-based models (Boltzmann machines), directed models (SBNs, VAEs), implicit models (GANs, GMMNs), and tractable auto-regressive models. Each class embodies a different compromise between <strong>expressivity</strong>, <strong>tractable inference</strong>, and <strong>trainability</strong>. The modern toolbox mixes these ideas, with approximate inference and stochastic optimization as the central enabling technologies. The chapter’s broader lesson is that there is no single “best” generative model. Choosing among likelihood-based, implicit, or hybrid approaches depends on the task: density estimation, sample generation, representation learning, or downstream decision-making. Understanding these tradeoffs lets you match the model family to the problem rather than forcing the problem to fit the model.</p>


<!-- -->

</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<input type="hidden" id="giscus-base-theme" value="light">
<input type="hidden" id="giscus-alt-theme" value="light">
<script>
  function loadGiscus() {
    // Function to get the theme based on body class
    const getTheme = () => {
      let baseTheme = document.getElementById('giscus-base-theme').value;
      let altTheme = document.getElementById('giscus-alt-theme').value;
      return document.body.classList.contains('quarto-dark') ? altTheme : baseTheme;
    };
    const script = document.createElement("script");
    script.src = "https://giscus.app/client.js";
    script.async = true;
    script.dataset.repo = "ickma2311/ickma2311.github.io";
    script.dataset.repoId = "R_kgDOOzbaAg";
    script.dataset.category = "Comments";
    script.dataset.categoryId = "DIC_kwDOOzbaAs4CxPFj";
    script.dataset.mapping = "pathname";
    script.dataset.reactionsEnabled = "1";
    script.dataset.emitMetadata = "0";
    script.dataset.inputPosition = "top";
    script.dataset.theme = getTheme();
    script.dataset.lang = "en";
    script.crossOrigin = "anonymous";
    // Append the script to the desired div instead of at the end of the body
    document.getElementById("quarto-content").appendChild(script);
  }
  loadGiscus();
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb1" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Goodfellow Deep Learning — Chapter 20: Deep Generative Models"</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span><span class="co"> "Chao Ma"</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> "2026-01-22"</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="an">categories:</span><span class="co"> [Deep Learning, Generative Models, Latent Variables, Approximate Inference]</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>Deep generative models describe probability distributions over many variables. Some models give an explicit density that can be evaluated; others only support operations that imply a distribution (such as sampling). Chapter 20 surveys the families that can be built from the tools of Chapters 16–19: graphical models, energy-based models, approximate inference, and stochastic optimization. The common thread is that **exact inference is rarely tractable**, so training relies on approximate objectives, clever factorization, or implicit learning signals.</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>Two complementary axes organize the landscape. First, **explicit vs implicit density**: energy-based models and autoregressive models define a normalized probability (or can estimate it), while adversarial or moment-matching models define a procedure that generates samples without an explicit likelihood. Second, **directed vs undirected structure**: directed models factorize via the chain rule, while undirected models encode dependencies symmetrically through energies. The chapter’s message is that every choice brings tradeoffs in tractability, sample quality, and optimization stability.</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="fu">## 20.1 Boltzmann machines</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>Boltzmann machines are **energy-based models** for binary vectors. The model defines a probability mass function through an energy function:</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>P(x)=\frac{\exp(-E(x))}{Z},</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>where the partition function $Z=\sum_x \exp(-E(x))$ normalizes the distribution. For a binary vector $x\in<span class="sc">\{</span>0,1<span class="sc">\}</span>^d$, a basic Boltzmann machine uses a quadratic energy</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>E(x)=-x^\top Ux-b^\top x,</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>with parameters $U$ and $b$. This already defines a valid distribution, but it limits interactions to those expressible through a pairwise quadratic form.</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>The model becomes much more expressive when we introduce **latent (hidden) units**. Splitting the variables into visible $v$ and hidden $h$, a general Boltzmann machine has energy</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>E(v,h)=-v^\top Rv - v^\top Wh - h^\top Sh - b^\top v - c^\top h.</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>With hidden units, the model can capture higher-order dependencies between visible variables and becomes a universal approximator of discrete distributions. The cost is that both the partition function and the posterior $p(h\mid v)$ are intractable in general, so exact learning and inference are not feasible.</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>Learning typically follows **maximum likelihood**, which yields gradients in terms of differences between statistics under the data and the model. The intractable expectations require approximations (e.g., MCMC), and training depends on techniques from Chapter 18.</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>Intuitively, the model increases probability mass near data points by decreasing energy in those regions, while the partition function pushes back by raising energy elsewhere. This tug-of-war is the “positive phase vs negative phase” structure shared by many energy-based models.</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a><span class="fu">## 20.2 Restricted Boltzmann machines (RBMs)</span></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>Restricted Boltzmann machines simplify the structure by making the graph **bipartite**: visible units connect only to hidden units, and there are no lateral connections within a layer. This restriction creates a useful conditional independence structure while retaining expressive power.</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>An RBM defines the joint distribution as</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>P(v,h)=\frac{1}{Z}\exp<span class="sc">\{</span>-E(v,h)<span class="sc">\}</span>,</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>with energy</span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>E(v,h)=-b^\top v - c^\top h - v^\top Wh.</span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a>Because of the bipartite graph, the conditional distributions factorize:</span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a>P(h\mid v)=\prod_i P(h_i\mid v),\quad P(v\mid h)=\prod_j P(v_j\mid h).</span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a>For binary units, each conditional is a sigmoid:</span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a>P(h_i=1\mid v)=\sigma(c_i + W_i^\top v),\quad P(v_j=1\mid h)=\sigma(b_j + W_j h).</span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a>This makes **inference and sampling** efficient via block Gibbs updates.</span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a><span class="fu">### 20.2.1 Conditional distributions</span></span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a>The key advantage of an RBM is that although $P(v)$ is intractable (because $Z$ is intractable), both conditionals are easy to compute and sample from. This enables a practical MCMC loop that alternates between sampling $h\sim P(h\mid v)$ and $v\sim P(v\mid h)$.</span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a><span class="fu">### 20.2.2 Training RBMs</span></span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a>RBMs are trained by maximum likelihood using approximate gradients. Because block Gibbs updates are efficient, standard methods from Chapter 18 are particularly convenient here:</span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Contrastive divergence (CD)**</span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Stochastic maximum likelihood / persistent CD (SML/PCD)**</span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Ratio matching**</span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a>The gradient of the log-likelihood involves a **data term** (expectation under $P(h\mid v)$ for data $v$) and a **model term** (expectation under the model distribution). The latter is approximated using the Markov chain. RBMs are among the most tractable undirected models used in deep learning because their conditionals are simple and their MCMC transitions mix relatively well compared to more general Boltzmann machines.</span>
<span id="cb1-67"><a href="#cb1-67" aria-hidden="true" tabindex="-1"></a>CD uses short chains initialized at data to approximate the negative phase, which is biased but often effective; PCD keeps a persistent chain to reduce bias at the cost of additional state. In practice, training stability depends on learning rates, regularization, and ensuring the chain does not drift too far from the data manifold.</span>
<span id="cb1-68"><a href="#cb1-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-69"><a href="#cb1-69" aria-hidden="true" tabindex="-1"></a><span class="fu">## 20.3 Deep belief networks (DBNs)</span></span>
<span id="cb1-70"><a href="#cb1-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-71"><a href="#cb1-71" aria-hidden="true" tabindex="-1"></a>Deep belief networks were one of the first successful deep probabilistic models and played a major role in the 2006 deep learning renaissance. A DBN stacks multiple layers of latent variables. It is **hybrid**:</span>
<span id="cb1-72"><a href="#cb1-72" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The top two layers form an undirected model (an RBM).</span>
<span id="cb1-73"><a href="#cb1-73" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Lower layers are directed generative connections.</span>
<span id="cb1-74"><a href="#cb1-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-75"><a href="#cb1-75" aria-hidden="true" tabindex="-1"></a>DBNs are trained **greedily** by stacking RBMs: each layer learns to model the hidden representation of the layer below. This provides a strong initialization for deep architectures that were otherwise difficult to optimize. After greedy pretraining, the model can be fine-tuned with approximate likelihood or a recognition network.</span>
<span id="cb1-76"><a href="#cb1-76" aria-hidden="true" tabindex="-1"></a>The greedy scheme can be understood as improving a variational lower bound on the data log-likelihood layer by layer. Even when the full model is not optimized end-to-end, the resulting latent hierarchy captures increasingly abstract features, which historically made DBNs useful for transfer and semi-supervised learning.</span>
<span id="cb1-77"><a href="#cb1-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-78"><a href="#cb1-78" aria-hidden="true" tabindex="-1"></a><span class="fu">## 20.4 Deep Boltzmann machines (DBMs)</span></span>
<span id="cb1-79"><a href="#cb1-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-80"><a href="#cb1-80" aria-hidden="true" tabindex="-1"></a>A DBM is a fully **undirected** model with multiple hidden layers. Like RBMs, it has a bipartite structure **between adjacent layers**, so units within a layer are conditionally independent given the neighboring layers. This yields a structured yet deep energy-based model.</span>
<span id="cb1-81"><a href="#cb1-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-82"><a href="#cb1-82" aria-hidden="true" tabindex="-1"></a>DBMs differ from DBNs in that **all layers are undirected**, and the posterior is closer to a factorial form, which enables richer variational approximations. The tradeoff is harder learning: both the partition function and the posterior are intractable.</span>
<span id="cb1-83"><a href="#cb1-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-84"><a href="#cb1-84" aria-hidden="true" tabindex="-1"></a><span class="fu">### 20.4.1 Interesting properties</span></span>
<span id="cb1-85"><a href="#cb1-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-86"><a href="#cb1-86" aria-hidden="true" tabindex="-1"></a>Compared to DBNs, DBMs have posterior distributions that are easier to approximate with mean-field methods, even though their graphical structure is deeper. This leads to more accurate approximate inference in some settings.</span>
<span id="cb1-87"><a href="#cb1-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-88"><a href="#cb1-88" aria-hidden="true" tabindex="-1"></a><span class="fu">### 20.4.2 Mean-field inference</span></span>
<span id="cb1-89"><a href="#cb1-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-90"><a href="#cb1-90" aria-hidden="true" tabindex="-1"></a>Mean-field inference approximates $p(h\mid v)$ with a factorized distribution $Q(h\mid v)=\prod_i q_i(h_i\mid v)$. The updates follow fixed-point equations derived from minimizing KL divergence. Because each layer is conditionally independent given its neighbors, the update for a unit depends only on expectations from adjacent layers, leading to iterative message passing.</span>
<span id="cb1-91"><a href="#cb1-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-92"><a href="#cb1-92" aria-hidden="true" tabindex="-1"></a><span class="fu">### 20.4.3 Parameter learning</span></span>
<span id="cb1-93"><a href="#cb1-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-94"><a href="#cb1-94" aria-hidden="true" tabindex="-1"></a>Learning combines two approximations:</span>
<span id="cb1-95"><a href="#cb1-95" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Stochastic maximum likelihood** to handle the intractable partition function.</span>
<span id="cb1-96"><a href="#cb1-96" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Variational inference** to handle the intractable posterior.</span>
<span id="cb1-97"><a href="#cb1-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-98"><a href="#cb1-98" aria-hidden="true" tabindex="-1"></a>The variational distribution provides an approximate “positive phase,” while MCMC provides the “negative phase.”</span>
<span id="cb1-99"><a href="#cb1-99" aria-hidden="true" tabindex="-1"></a>DBMs are conceptually appealing because they define a single coherent undirected distribution over all layers, but in practice they are sensitive to initialization and require careful tuning to avoid poor local optima.</span>
<span id="cb1-100"><a href="#cb1-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-101"><a href="#cb1-101" aria-hidden="true" tabindex="-1"></a><span class="fu">### 20.4.4 Layer-wise pretraining</span></span>
<span id="cb1-102"><a href="#cb1-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-103"><a href="#cb1-103" aria-hidden="true" tabindex="-1"></a>Training a DBM from random initialization often fails: it can collapse to an RBM-like solution where upper layers are unused. Greedy layer-wise pretraining (via RBMs) helps initialize each layer with meaningful structure, preventing the model from ignoring deeper layers.</span>
<span id="cb1-104"><a href="#cb1-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-105"><a href="#cb1-105" aria-hidden="true" tabindex="-1"></a><span class="fu">### 20.4.5 Joint training</span></span>
<span id="cb1-106"><a href="#cb1-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-107"><a href="#cb1-107" aria-hidden="true" tabindex="-1"></a>Greedy pretraining has drawbacks (slow feedback, difficult hyperparameter tuning). Joint training attempts to optimize all layers together, often using a recognition network to initialize variational inference. This improves end-to-end learning but is more complex to implement.</span>
<span id="cb1-108"><a href="#cb1-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-109"><a href="#cb1-109" aria-hidden="true" tabindex="-1"></a><span class="fu">## 20.5 Boltzmann machines for real-valued data</span></span>
<span id="cb1-110"><a href="#cb1-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-111"><a href="#cb1-111" aria-hidden="true" tabindex="-1"></a>Many real-world data types are continuous. There are two strategies:</span>
<span id="cb1-112"><a href="#cb1-112" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Treat a real value in $<span class="co">[</span><span class="ot">0,1</span><span class="co">]</span>$ as the mean of a Bernoulli (approximation).</span>
<span id="cb1-113"><a href="#cb1-113" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Use **Gaussian visible units**, yielding Gaussian–Bernoulli RBMs.</span>
<span id="cb1-114"><a href="#cb1-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-115"><a href="#cb1-115" aria-hidden="true" tabindex="-1"></a>Gaussian–Bernoulli RBMs replace the binary visible distribution with a Gaussian conditional. The energy function is adjusted accordingly, leading to linear Gaussian conditionals for visibles and logistic conditionals for hiddens. This supports modeling real-valued data such as images and audio.</span>
<span id="cb1-116"><a href="#cb1-116" aria-hidden="true" tabindex="-1"></a>When using Gaussian visibles, the variance can be fixed or learned. Fixing variance simplifies training but may underfit; learning variance increases flexibility but can destabilize optimization without appropriate constraints or priors.</span>
<span id="cb1-117"><a href="#cb1-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-118"><a href="#cb1-118" aria-hidden="true" tabindex="-1"></a><span class="fu">### 20.5.1 Gaussian–Bernoulli RBMs</span></span>
<span id="cb1-119"><a href="#cb1-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-120"><a href="#cb1-120" aria-hidden="true" tabindex="-1"></a>A Gaussian–Bernoulli RBM keeps hidden units binary but makes visible units Gaussian. This allows real-valued observations while preserving efficient conditional sampling.</span>
<span id="cb1-121"><a href="#cb1-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-122"><a href="#cb1-122" aria-hidden="true" tabindex="-1"></a><span class="fu">### 20.5.2 Conditional covariance models</span></span>
<span id="cb1-123"><a href="#cb1-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-124"><a href="#cb1-124" aria-hidden="true" tabindex="-1"></a>RBMs can be extended to model not only means but also **conditional covariance structure**. These models capture second-order dependencies in real-valued data by introducing interactions that change variance as a function of the hidden state.</span>
<span id="cb1-125"><a href="#cb1-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-126"><a href="#cb1-126" aria-hidden="true" tabindex="-1"></a><span class="fu">## 20.6 Convolutional Boltzmann machines</span></span>
<span id="cb1-127"><a href="#cb1-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-128"><a href="#cb1-128" aria-hidden="true" tabindex="-1"></a>Convolutional structure introduces **weight sharing and locality**, making the model more suitable for images. Convolutional RBMs learn filters that are applied across spatial locations, producing hidden feature maps. Pooling or subsampling operations can be used to gain translation invariance and reduce spatial resolution while maintaining probabilistic semantics.</span>
<span id="cb1-129"><a href="#cb1-129" aria-hidden="true" tabindex="-1"></a>These models connect classical probabilistic learning with modern convolutional architectures: feature maps act like latent detectors, and shared filters encourage the model to reuse visual primitives. Training still relies on CD or PCD, but the convolutional structure reduces parameter count and tends to improve sample quality for image-like data.</span>
<span id="cb1-130"><a href="#cb1-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-131"><a href="#cb1-131" aria-hidden="true" tabindex="-1"></a><span class="fu">## 20.7 Boltzmann machines for structured or sequential data</span></span>
<span id="cb1-132"><a href="#cb1-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-133"><a href="#cb1-133" aria-hidden="true" tabindex="-1"></a>Boltzmann machines can be adapted to sequences or structured outputs by conditioning on context or introducing temporal connections. For example, conditional RBMs incorporate past observations, and structured RBMs can encode constraints that tie together multiple variables across time or spatial layouts.</span>
<span id="cb1-134"><a href="#cb1-134" aria-hidden="true" tabindex="-1"></a>Temporal extensions treat each time step as a visible layer connected to hidden variables that summarize history. This makes the model suitable for motion capture or sequence prediction, where the latent state captures dynamics while the visible units represent observations.</span>
<span id="cb1-135"><a href="#cb1-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-136"><a href="#cb1-136" aria-hidden="true" tabindex="-1"></a><span class="fu">## 20.8 Other Boltzmann machines</span></span>
<span id="cb1-137"><a href="#cb1-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-138"><a href="#cb1-138" aria-hidden="true" tabindex="-1"></a>The Boltzmann framework supports many variants: different variable types, structured connectivity, and specialized energies. These variants aim to balance expressivity with tractable inference or efficient sampling.</span>
<span id="cb1-139"><a href="#cb1-139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-140"><a href="#cb1-140" aria-hidden="true" tabindex="-1"></a><span class="fu">## 20.9 Back-propagation through random operations</span></span>
<span id="cb1-141"><a href="#cb1-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-142"><a href="#cb1-142" aria-hidden="true" tabindex="-1"></a>Training generative models often requires gradients through **stochastic nodes**. When outputs depend on random sampling, naive back-propagation fails. Two main ideas appear:</span>
<span id="cb1-143"><a href="#cb1-143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-144"><a href="#cb1-144" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Reparameterization-style gradients**: express a random variable as a deterministic function of noise, enabling gradients to pass through the deterministic transformation.</span>
<span id="cb1-145"><a href="#cb1-145" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Score-function estimators** (likelihood-ratio / REINFORCE): move the gradient inside the expectation using</span>
<span id="cb1-146"><a href="#cb1-146" aria-hidden="true" tabindex="-1"></a>  $$</span>
<span id="cb1-147"><a href="#cb1-147" aria-hidden="true" tabindex="-1"></a>  \nabla_\theta \mathbb{E}_{x\sim p_\theta}[f(x)] = \mathbb{E}_{x\sim p_\theta}[f(x)\nabla_\theta \log p_\theta(x)].</span>
<span id="cb1-148"><a href="#cb1-148" aria-hidden="true" tabindex="-1"></a>  $$</span>
<span id="cb1-149"><a href="#cb1-149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-150"><a href="#cb1-150" aria-hidden="true" tabindex="-1"></a><span class="fu">### 20.9.1 Discrete stochastic operations</span></span>
<span id="cb1-151"><a href="#cb1-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-152"><a href="#cb1-152" aria-hidden="true" tabindex="-1"></a>Discrete random variables make reparameterization difficult, so score-function estimators are common. These estimators are unbiased but can have high variance, motivating variance-reduction tricks such as baselines or control variates.</span>
<span id="cb1-153"><a href="#cb1-153" aria-hidden="true" tabindex="-1"></a>Reparameterization is especially effective for continuous latent variables: sampling $z=\mu+\sigma\odot\epsilon$ with $\epsilon\sim\mathcal{N}(0,I)$ turns a stochastic node into a differentiable function of noise, which dramatically reduces gradient variance compared to score-function estimators.</span>
<span id="cb1-154"><a href="#cb1-154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-155"><a href="#cb1-155" aria-hidden="true" tabindex="-1"></a><span class="fu">## 20.10 Directed generative networks</span></span>
<span id="cb1-156"><a href="#cb1-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-157"><a href="#cb1-157" aria-hidden="true" tabindex="-1"></a>Directed models represent joint distributions via the chain rule and conditional distributions defined by neural networks. These models became prominent in deep learning after 2013, complementing undirected approaches like RBMs.</span>
<span id="cb1-158"><a href="#cb1-158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-159"><a href="#cb1-159" aria-hidden="true" tabindex="-1"></a><span class="fu">### 20.10.1 Sigmoid belief networks</span></span>
<span id="cb1-160"><a href="#cb1-160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-161"><a href="#cb1-161" aria-hidden="true" tabindex="-1"></a>A sigmoid belief network (SBN) is a directed graphical model with binary units. Each unit’s activation is determined by a sigmoid of weighted inputs from its parents. This is a probabilistic analogue of a multilayer perceptron, but with latent randomness.</span>
<span id="cb1-162"><a href="#cb1-162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-163"><a href="#cb1-163" aria-hidden="true" tabindex="-1"></a><span class="fu">### 20.10.2 Differentiable generator networks</span></span>
<span id="cb1-164"><a href="#cb1-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-165"><a href="#cb1-165" aria-hidden="true" tabindex="-1"></a>A general strategy for generative modeling is to map latent variables $z$ to data space using a differentiable function $g(z;\theta)$. Sampling is easy: draw $z\sim p(z)$ and compute $x=g(z;\theta)$. The challenge is learning $\theta$, which depends on the training criterion (ELBO, adversarial loss, moment matching, etc.).</span>
<span id="cb1-166"><a href="#cb1-166" aria-hidden="true" tabindex="-1"></a>Depending on the loss, the same generator can behave very differently. Maximum-likelihood or ELBO objectives emphasize coverage of the data distribution (discouraging missing modes), while adversarial or moment-matching objectives may emphasize sharp, realistic samples even if some modes are dropped. This explains why different families are favored for different goals.</span>
<span id="cb1-167"><a href="#cb1-167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-168"><a href="#cb1-168" aria-hidden="true" tabindex="-1"></a><span class="fu">### 20.10.3 Variational autoencoders (VAEs)</span></span>
<span id="cb1-169"><a href="#cb1-169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-170"><a href="#cb1-170" aria-hidden="true" tabindex="-1"></a>A VAE combines a generator network with an **inference network** that approximates the posterior. Training maximizes the ELBO using reparameterization. The model defines</span>
<span id="cb1-171"><a href="#cb1-171" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-172"><a href="#cb1-172" aria-hidden="true" tabindex="-1"></a> p(z)p(x\mid z),</span>
<span id="cb1-173"><a href="#cb1-173" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-174"><a href="#cb1-174" aria-hidden="true" tabindex="-1"></a>and learns an encoder $q(z\mid x)$ for approximate inference. VAEs provide a principled likelihood-based model with efficient training.</span>
<span id="cb1-175"><a href="#cb1-175" aria-hidden="true" tabindex="-1"></a>The ELBO decomposes into a reconstruction term and a KL regularizer:</span>
<span id="cb1-176"><a href="#cb1-176" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-177"><a href="#cb1-177" aria-hidden="true" tabindex="-1"></a>\mathbb{E}_{q(z\mid x)}[\log p(x\mid z)] - D_{\mathrm{KL}}(q(z\mid x)<span class="sc">\|</span>p(z)).</span>
<span id="cb1-178"><a href="#cb1-178" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-179"><a href="#cb1-179" aria-hidden="true" tabindex="-1"></a>This highlights the tradeoff between fidelity to data and keeping the approximate posterior close to the prior. Variants such as $\beta$-VAE adjust this balance to encourage disentangled latents.</span>
<span id="cb1-180"><a href="#cb1-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-181"><a href="#cb1-181" aria-hidden="true" tabindex="-1"></a><span class="fu">### 20.10.4 Generative adversarial networks (GANs)</span></span>
<span id="cb1-182"><a href="#cb1-182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-183"><a href="#cb1-183" aria-hidden="true" tabindex="-1"></a>GANs set up a two-player game between a generator and a discriminator. The generator tries to produce samples that fool the discriminator, while the discriminator learns to distinguish real from generated data. GANs avoid explicit likelihood evaluation and often produce sharp samples but can be unstable to train.</span>
<span id="cb1-184"><a href="#cb1-184" aria-hidden="true" tabindex="-1"></a>The original GAN objective corresponds to minimizing the Jensen–Shannon divergence between model and data distributions. Instability issues like mode collapse motivate alternative losses (e.g., Wasserstein GAN) and regularization strategies that improve gradient behavior.</span>
<span id="cb1-185"><a href="#cb1-185" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-186"><a href="#cb1-186" aria-hidden="true" tabindex="-1"></a><span class="fu">### 20.10.5 Generative moment matching networks (GMMNs)</span></span>
<span id="cb1-187"><a href="#cb1-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-188"><a href="#cb1-188" aria-hidden="true" tabindex="-1"></a>GMMNs train a generator so that **statistics (moments)** of generated samples match those of real data. This is often done with kernel-based discrepancy measures (e.g., maximum mean discrepancy). No inference network or discriminator is required, but the choice of moments critically affects performance.</span>
<span id="cb1-189"><a href="#cb1-189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-190"><a href="#cb1-190" aria-hidden="true" tabindex="-1"></a><span class="fu">### 20.10.6 Convolutional generative networks</span></span>
<span id="cb1-191"><a href="#cb1-191" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-192"><a href="#cb1-192" aria-hidden="true" tabindex="-1"></a>For images, generator networks benefit from convolutional structure and transpose convolutions. This leverages locality and parameter sharing, often improving sample quality and reducing parameter count.</span>
<span id="cb1-193"><a href="#cb1-193" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-194"><a href="#cb1-194" aria-hidden="true" tabindex="-1"></a><span class="fu">### 20.10.7 Auto-regressive networks</span></span>
<span id="cb1-195"><a href="#cb1-195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-196"><a href="#cb1-196" aria-hidden="true" tabindex="-1"></a>Auto-regressive models factorize the joint distribution via the chain rule:</span>
<span id="cb1-197"><a href="#cb1-197" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-198"><a href="#cb1-198" aria-hidden="true" tabindex="-1"></a>P(x)=\prod_i P(x_i\mid x_{&lt;i}).</span>
<span id="cb1-199"><a href="#cb1-199" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-200"><a href="#cb1-200" aria-hidden="true" tabindex="-1"></a>They can achieve exact likelihoods but require sequential sampling. They contain **no latent variables**, relying instead on conditional distributions modeled by neural networks.</span>
<span id="cb1-201"><a href="#cb1-201" aria-hidden="true" tabindex="-1"></a>Examples like PixelRNN and PixelCNN demonstrate how autoregressive factorization can yield state-of-the-art density estimation for images, at the cost of slow sampling because each pixel must be generated in sequence.</span>
<span id="cb1-202"><a href="#cb1-202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-203"><a href="#cb1-203" aria-hidden="true" tabindex="-1"></a><span class="fu">### 20.10.8 Linear auto-regressive networks</span></span>
<span id="cb1-204"><a href="#cb1-204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-205"><a href="#cb1-205" aria-hidden="true" tabindex="-1"></a>The simplest auto-regressive models use linear predictors (e.g., logistic regression for binary data). They are conceptually straightforward but may lack capacity for complex data distributions.</span>
<span id="cb1-206"><a href="#cb1-206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-207"><a href="#cb1-207" aria-hidden="true" tabindex="-1"></a><span class="fu">### 20.10.9 Neural auto-regressive networks</span></span>
<span id="cb1-208"><a href="#cb1-208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-209"><a href="#cb1-209" aria-hidden="true" tabindex="-1"></a>Neural auto-regressive networks use nonlinear hidden layers and parameter sharing to improve expressivity. This creates powerful density estimators with tractable likelihoods.</span>
<span id="cb1-210"><a href="#cb1-210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-211"><a href="#cb1-211" aria-hidden="true" tabindex="-1"></a><span class="fu">### 20.10.10 NADE</span></span>
<span id="cb1-212"><a href="#cb1-212" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-213"><a href="#cb1-213" aria-hidden="true" tabindex="-1"></a>The Neural Auto-Regressive Density Estimator (NADE) introduces a specific parameter-sharing scheme that makes training efficient while retaining strong modeling power. NADE is widely used as a tractable alternative to RBMs for certain data types.</span>
<span id="cb1-214"><a href="#cb1-214" aria-hidden="true" tabindex="-1"></a>NADE’s main appeal is that it provides **exact log-likelihood** and efficient training via maximum likelihood, avoiding MCMC. It can be seen as an autoregressive model with shared weights that reuse hidden activations across conditional distributions, making it a practical density estimator for moderate-dimensional data.</span>
<span id="cb1-215"><a href="#cb1-215" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-216"><a href="#cb1-216" aria-hidden="true" tabindex="-1"></a><span class="fu">## 20.11 Drawing samples from autoencoders</span></span>
<span id="cb1-217"><a href="#cb1-217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-218"><a href="#cb1-218" aria-hidden="true" tabindex="-1"></a>Autoencoders can define implicit generative models by constructing a Markov chain. For denoising autoencoders, the transition consists of corrupting a sample and then denoising it. Repeating this process yields samples from an implicit distribution.</span>
<span id="cb1-219"><a href="#cb1-219" aria-hidden="true" tabindex="-1"></a>These models blur the line between encoder-decoder representation learning and generative modeling: the decoder learns to map noisy points back to the data manifold, and the resulting chain can be interpreted as sampling from that manifold.</span>
<span id="cb1-220"><a href="#cb1-220" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-221"><a href="#cb1-221" aria-hidden="true" tabindex="-1"></a><span class="fu">### 20.11.1 Associated Markov chain</span></span>
<span id="cb1-222"><a href="#cb1-222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-223"><a href="#cb1-223" aria-hidden="true" tabindex="-1"></a>A denoising autoencoder defines a transition kernel that alternates between corruption and reconstruction. Under suitable conditions, this Markov chain has a stationary distribution related to the data distribution.</span>
<span id="cb1-224"><a href="#cb1-224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-225"><a href="#cb1-225" aria-hidden="true" tabindex="-1"></a><span class="fu">### 20.11.2 Clamping and conditional sampling</span></span>
<span id="cb1-226"><a href="#cb1-226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-227"><a href="#cb1-227" aria-hidden="true" tabindex="-1"></a>By clamping some variables and running the chain on the rest, the model can perform conditional generation or inpainting.</span>
<span id="cb1-228"><a href="#cb1-228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-229"><a href="#cb1-229" aria-hidden="true" tabindex="-1"></a><span class="fu">### 20.11.3 Walk-back training</span></span>
<span id="cb1-230"><a href="#cb1-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-231"><a href="#cb1-231" aria-hidden="true" tabindex="-1"></a>Walk-back training improves denoising autoencoders by training them on samples drawn from the model’s own Markov chain, reducing spurious modes and encouraging the model to “walk back” toward the data manifold.</span>
<span id="cb1-232"><a href="#cb1-232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-233"><a href="#cb1-233" aria-hidden="true" tabindex="-1"></a><span class="fu">## 20.12 Generative stochastic networks (GSNs)</span></span>
<span id="cb1-234"><a href="#cb1-234" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-235"><a href="#cb1-235" aria-hidden="true" tabindex="-1"></a>GSNs generalize denoising autoencoders by defining a stochastic transition operator for a Markov chain. The model is trained so that the chain’s stationary distribution matches the data distribution. Unlike RBMs, GSNs do not require an explicit energy function or partition function.</span>
<span id="cb1-236"><a href="#cb1-236" aria-hidden="true" tabindex="-1"></a>Viewed through a modern lens, GSNs relate to **score matching** and diffusion-style ideas: learning to denoise implicitly estimates the score (the gradient of log density), and repeated denoising steps form a sampler that moves toward high-density regions.</span>
<span id="cb1-237"><a href="#cb1-237" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-238"><a href="#cb1-238" aria-hidden="true" tabindex="-1"></a><span class="fu">### 20.12.1 Discriminant GSNs</span></span>
<span id="cb1-239"><a href="#cb1-239" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-240"><a href="#cb1-240" aria-hidden="true" tabindex="-1"></a>Discriminant GSNs incorporate supervised signals while maintaining a generative interpretation, enabling semi-supervised or structured prediction tasks.</span>
<span id="cb1-241"><a href="#cb1-241" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-242"><a href="#cb1-242" aria-hidden="true" tabindex="-1"></a><span class="fu">## 20.13 Other generation schemes</span></span>
<span id="cb1-243"><a href="#cb1-243" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-244"><a href="#cb1-244" aria-hidden="true" tabindex="-1"></a>The chapter also highlights alternative generative strategies that do not fit neatly into RBM, VAE, or GAN categories. The unifying theme is trading off **tractability**, **sample quality**, and **training stability** depending on the model family and objective.</span>
<span id="cb1-245"><a href="#cb1-245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-246"><a href="#cb1-246" aria-hidden="true" tabindex="-1"></a><span class="fu">## 20.14 Evaluating generative models</span></span>
<span id="cb1-247"><a href="#cb1-247" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-248"><a href="#cb1-248" aria-hidden="true" tabindex="-1"></a>Evaluating generative models is subtle. Sometimes we can compute exact log-likelihoods; other times we only have stochastic estimates or lower bounds. Comparing models under different evaluation criteria can be misleading. The key is to be explicit about what is measured:</span>
<span id="cb1-249"><a href="#cb1-249" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Exact log-likelihood vs. approximate estimates</span>
<span id="cb1-250"><a href="#cb1-250" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Lower bounds vs. unbiased estimators</span>
<span id="cb1-251"><a href="#cb1-251" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Sample quality vs. density quality</span>
<span id="cb1-252"><a href="#cb1-252" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-253"><a href="#cb1-253" aria-hidden="true" tabindex="-1"></a>Evaluation should align with the intended use: density estimation, sampling quality, or downstream task performance.</span>
<span id="cb1-254"><a href="#cb1-254" aria-hidden="true" tabindex="-1"></a>Common proxy metrics like the Inception Score or FID measure sample quality using pretrained classifiers, but they do not directly reflect likelihood. Recent work proposes precision/recall decompositions to characterize both fidelity and diversity, emphasizing that no single metric captures all desired properties.</span>
<span id="cb1-255"><a href="#cb1-255" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-256"><a href="#cb1-256" aria-hidden="true" tabindex="-1"></a><span class="fu">## 20.15 Conclusion</span></span>
<span id="cb1-257"><a href="#cb1-257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-258"><a href="#cb1-258" aria-hidden="true" tabindex="-1"></a>Deep generative modeling spans a wide family: energy-based models (Boltzmann machines), directed models (SBNs, VAEs), implicit models (GANs, GMMNs), and tractable auto-regressive models. Each class embodies a different compromise between **expressivity**, **tractable inference**, and **trainability**. The modern toolbox mixes these ideas, with approximate inference and stochastic optimization as the central enabling technologies.</span>
<span id="cb1-259"><a href="#cb1-259" aria-hidden="true" tabindex="-1"></a>The chapter’s broader lesson is that there is no single “best” generative model. Choosing among likelihood-based, implicit, or hybrid approaches depends on the task: density estimation, sample generation, representation learning, or downstream decision-making. Understanding these tradeoffs lets you match the model family to the problem rather than forcing the problem to fit the model.</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></div>
</div></div></div></div></div>
</div> <!-- /content -->




</body></html>