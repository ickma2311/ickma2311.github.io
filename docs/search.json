[
  {
    "objectID": "ML/kmeans.html",
    "href": "ML/kmeans.html",
    "title": "K-means Clustering",
    "section": "",
    "text": "Setup points and K\nwe will implement a KNN algorithm to cluster the points\n\n\nX=[[1,1],[2,2.1],[3,2.5],[6,7],[7,7.1],[9,7.5]]\nk=2\n\nmax_iter=3\n\n\n# Visualize the data\n\n\nimport matplotlib.pyplot as plt\n\nplt.scatter([x[0] for x in X],[x[1] for x in X])\nplt.show()\n\n\n\n\n\n\n\n\n\n# Pure python implementation of K-means clustering\ndef knn_iter(X,centroids):\n    # set up new clusters\n    new_clusters=[[] for _ in range(len(centroids))]\n    # k=len(centroids)\n    # assign each point to the nearest centroid\n    for x in X:\n        k,distance=0,(x[0]-centroids[0][0])**2+(x[1]-centroids[0][1])**2\n        for i,c in enumerate(centroids[1:],1):\n            if (x[0]-c[0])**2+(x[1]-c[1])**2&lt;distance:\n                k=i\n                distance=(x[0]-c[0])**2+(x[1]-c[1])**2\n        new_clusters[k].append(x)\n    \n    # calculate new centroids\n    new_centroids=[[\n        sum([x[0] for x in cluster])/len(cluster),\n        sum([x[1] for x in cluster])/len(cluster)\n    ] if cluster else centroids[i] for i,cluster in enumerate(new_clusters)]\n    return new_centroids\n\n\n\n\n\n\n\n\ndef iter_and_draw(X,k,max_iter):\n    centroids=X[:k]  # Randomly select 2 centroids\n    fig, axes = plt.subplots(max_iter//3+(1 if max_iter%3!=0 else 0),\n        3, figsize=(15, 10))\n    axes=axes.flatten()\n    for i in range(max_iter):\n        \n        # Plot points and centroids\n\n\n        # Assign each point to nearest centroid and plot with corresponding color\n        colors = ['blue', 'green', 'purple', 'orange', 'brown', 'pink', 'gray', 'olive', 'cyan']\n        for j, x in enumerate(X):\n            # Find nearest centroid\n            min_dist = float('inf')\n            nearest_centroid = 0\n            for k, c in enumerate(centroids):\n                dist = (x[0]-c[0])**2 + (x[1]-c[1])**2\n                if dist &lt; min_dist:\n                    min_dist = dist\n                    nearest_centroid = k\n            # Plot point with color corresponding to its cluster\n            axes[i].scatter(x[0], x[1], c=colors[nearest_centroid % len(colors)], label=f'Cluster {nearest_centroid+1}' if j==0 else \"\")\n        axes[i].scatter([c[0] for c in centroids], [c[1] for c in centroids], c='red', marker='*', s=200, label='Centroids')\n        axes[i].set_title(f'Iteration {i}')\n        centroids = knn_iter(X, centroids)\n\n    plt.tight_layout()\n    plt.show()\n\niter_and_draw(X,k,max_iter)\n# print(centroids)\n\n\n\n\n\n\n\n\n\n# A 3 clusters example\n\nimport numpy as np\n\nX1=np.random.rand(20,2)+5 # Some points in the upper right corner\nX2=np.random.rand(20,2)+3 # Some points in the middle\nX3=np.random.rand(20,2) # Some points in the lower left corner\n\niter_and_draw(np.concatenate((X1,X2,X3)),3,5)\n\n\n\n\n\n\n\n\n\n\nA question?\n\nWhat to do if one cluster has no assigned points during iteration?\n\n\n\nFormula Derivation\nThe goal is to minimize the loss of inertia which is sum of the points to cluster centroids.\n\\[\nLoss= \\sum_{i=1}^n \\sum_{x \\in C_i} ||x-\\mu_i||^2\n\\]\nTo iter \\(\\mu\\) for each cluster, let us find the derivative of the following function. \\[\nf(\\mu)=\\sum_{i=1}^n ||x_i-\\mu||^2 =\n\\sum_{i=1}^n {x_i}^2+\\mu^2-2x_i\\mu\n\\]\nGiven a \\(\\nabla \\mu\\), \\[\nf(\\mu + \\nabla \\mu)=\\sum_{i=1}^n ||x_i+\\nabla \\mu -\\mu||^2 =\n\\sum_{i=1}^n  {x_i}^2+\\mu^2+{\\nabla \\mu}^2-2{x_i \\mu}-2{\\mu \\nabla \\mu}+2{x_i \\nabla \\mu}\n\\]\n\\[\nf(\\mu + \\nabla \\mu)-f(\\mu)=\n\\sum_{i=1}^n {\\nabla \\mu}^2-2{\\mu \\nabla \\mu}+2{x_i \\nabla \\mu}\n\\]\n\\[\n\\frac {f(\\mu + \\nabla \\mu)-f(\\mu)}{\\nabla \\mu}=\\sum_{i=1}^n {\\nabla \\mu} -2 \\mu +2{x_i} = 2\\sum_{i=1}^n x_i - 2n\\mu\n\\]\nNow we can see if \\(n\\mu = \\sum_{i=1}^n x_i\\), then the derivative is 0, this is why in each iteration, we need to set the center of the cluster as centroid."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ickma.dev",
    "section": "",
    "text": "A growing collection of structured study notes and visual explanations ‚Äî written for clarity, reproducibility, and long-term memory."
  },
  {
    "objectID": "index.html#latest-updates",
    "href": "index.html#latest-updates",
    "title": "ickma.dev",
    "section": "Latest Updates",
    "text": "Latest Updates\n\n‚àá Deep Learning Book 35 chapters\nMy notes on the Deep Learning book by Ian Goodfellow, Yoshua Bengio, and Aaron Courville.\n\n\nChapter 9.7: Data Types CNNs can operate on different data types: 1D (audio, time series), 2D (images), and 3D (videos, CT scans) with varying channel counts. Unlike fully connected networks, convolutional kernels handle variable-sized inputs‚Äîa unique flexibility for diverse domains.\n\n\nChapter 9.6: Structured Outputs CNNs can generate high-dimensional structured objects through pixel-level predictions. Recurrent convolution refines predictions iteratively, producing dense outputs for segmentation, depth estimation, and flow prediction.\n\n\nChapter 9.5: Convolutional Functions Mathematical details of convolution operations: deep learning uses cross-correlation (not true convolution), multi-channel formula \\(Z_{l,x,y} = \\sum_{i,j,k} V_{i,x+j-1,y+k-1} K_{l,i,j,k}\\), stride for downsampling, three padding strategies (valid/same/full), and gradient computation.\n\n\nChapter 9.4: Convolution and Pooling as an Infinitely Strong Prior Why CNNs work on images but not everywhere: architectural constraints (local connectivity + weight sharing) act as infinitely strong Bayesian priors, assigning probability 1 to translation-equivariant functions and 0 to all others.\n\n\n\nSee all Deep Learning chapters ‚Üí\n\n\n\nüìê MIT 18.06SC Linear Algebra 36 lectures\nMy journey through MIT‚Äôs Linear Algebra course, focusing on building intuition and making connections between fundamental concepts.\n\n\nLecture 27: Positive Definite Matrices and Minima Connecting positive definite matrices to multivariable calculus and optimization: the Hessian matrix, second derivative tests, and the geometric interpretation of quadratic forms as ellipsoids.\n\n\nLecture 26: Complex Matrices and Fast Fourier Transform Extending linear algebra to complex vectors: Hermitian matrices, unitary matrices, and the Fast Fourier Transform algorithm that reduces DFT complexity from O(N¬≤) to O(N log N).\n\n\nLecture 28: Similar Matrices and Jordan Form When matrices share eigenvalues but differ in structure: similar matrices represent the same transformation in different bases, and Jordan form reveals the canonical structure when diagonalization fails.\n\n\nLecture 25: Symmetric Matrices and Positive Definiteness The beautiful structure of symmetric matrices: real eigenvalues, orthogonal eigenvectors, spectral decomposition, and the important concept of positive definiteness.\n\n\n\nSee all MIT 18.06SC lectures ‚Üí\n\n\n\nüìê MIT 18.065 Matrix Methods 1 lecture\nMy notes from MIT 18.065 Matrix Methods in Data Analysis, Signal Processing, and Machine Learning.\n\n\nLecture 8: Norms of Vectors and Matrices Understanding vector p-norms (\\(\\|v\\|_p\\)) and when they satisfy the triangle inequality (only for \\(p \\geq 1\\)). The ‚Äú\\(\\frac{1}{2}\\)-norm‚Äù creates non-convex unit balls for strong sparsity.\n\n\n\nSee all MIT 18.065 lectures ‚Üí"
  },
  {
    "objectID": "index.html#more-topics",
    "href": "index.html#more-topics",
    "title": "ickma.dev",
    "section": "More Topics",
    "text": "More Topics\n\n\nMachine Learning\n\nK-Means Clustering\nLogistic Regression\nAxis Operations\n\n\n\nAlgorithms\n\nDP Regex"
  },
  {
    "objectID": "ML/cnn-data-types.html",
    "href": "ML/cnn-data-types.html",
    "title": "Chapter 9.7: Data Types",
    "section": "",
    "text": "Convolutional networks can operate on many different kinds of data, depending on the number of channels and the dimensionality of the input."
  },
  {
    "objectID": "ML/cnn-data-types.html#overview",
    "href": "ML/cnn-data-types.html#overview",
    "title": "Chapter 9.7: Data Types",
    "section": "",
    "text": "Convolutional networks can operate on many different kinds of data, depending on the number of channels and the dimensionality of the input."
  },
  {
    "objectID": "ML/cnn-data-types.html#input-formats",
    "href": "ML/cnn-data-types.html#input-formats",
    "title": "Chapter 9.7: Data Types",
    "section": "Input Formats",
    "text": "Input Formats\nTable 9.1 illustrates how 1D, 2D, and 3D inputs can each appear in both single-channel and multi-channel forms.\n Figure: Examples of different data types CNNs can process. 1D inputs include audio waveforms and time series. 2D inputs include grayscale images (single-channel) and RGB images (multi-channel). 3D inputs correspond to volumes such as CT scans (single-channel) or videos and skeleton animations (multi-channel spatiotemporal data).\n\n1D inputs include audio waveforms, time series, or multi-sensor signals.\n2D inputs include grayscale images (single-channel) and RGB or multispectral images (multi-channel).\n3D inputs correspond to volumes such as CT scans (single-channel) or videos and skeleton animations (multi-channel spatiotemporal data)."
  },
  {
    "objectID": "ML/cnn-data-types.html#flexibility-of-convolution",
    "href": "ML/cnn-data-types.html#flexibility-of-convolution",
    "title": "Chapter 9.7: Data Types",
    "section": "Flexibility of Convolution",
    "text": "Flexibility of Convolution\nOne advantage of convolution is that it naturally supports these different input structures without requiring a fixed dimensionality or a fixed number of channels.\nThe same convolutional kernel can be applied across various data types because convolution is fundamentally a translation-equivariant, local operation."
  },
  {
    "objectID": "ML/cnn-data-types.html#variable-sized-inputs",
    "href": "ML/cnn-data-types.html#variable-sized-inputs",
    "title": "Chapter 9.7: Data Types",
    "section": "Variable-Sized Inputs",
    "text": "Variable-Sized Inputs\nAdditionally, convolution can also process variable-sized inputs.\nAs long as the kernel size is fixed, the convolution operation slides across the input regardless of its spatial extent, producing outputs whose dimensions scale accordingly.\nThis flexibility enables CNNs to handle inputs with different widths or heights‚Äîa property that fully connected networks do not have.\n Figure: CNNs can process inputs of different sizes. The same convolutional kernel slides across inputs regardless of spatial extent, producing outputs that scale with the input dimensions. This flexibility is unique to convolutional architectures‚Äîfully connected networks require fixed-size inputs."
  },
  {
    "objectID": "ML/cnn-data-types.html#key-insight",
    "href": "ML/cnn-data-types.html#key-insight",
    "title": "Chapter 9.7: Data Types",
    "section": "Key Insight",
    "text": "Key Insight\nThe power of CNNs lies in their flexibility. Unlike fully connected networks that require fixed input dimensions, convolutional networks can handle varying channel counts, different spatial dimensionalities (1D, 2D, 3D), and variable-sized inputs‚Äîall with the same kernel. This versatility makes CNNs applicable to a wide range of domains beyond computer vision, from audio processing to volumetric medical imaging."
  },
  {
    "objectID": "CLAUDE.html",
    "href": "CLAUDE.html",
    "title": "",
    "section": "",
    "text": "Code"
  },
  {
    "objectID": "CLAUDE.html#project-overview",
    "href": "CLAUDE.html#project-overview",
    "title": "",
    "section": "Project Overview",
    "text": "Project Overview\nThis is a Quarto-based technical blog hosted on GitHub Pages (ickma2311.github.io). The site covers machine learning, algorithms, and technical tutorials with a focus on mathematical foundations and practical implementations."
  },
  {
    "objectID": "CLAUDE.html#common-commands",
    "href": "CLAUDE.html#common-commands",
    "title": "",
    "section": "Common Commands",
    "text": "Common Commands\n\nDevelopment Workflow\n\nquarto render - Build the entire website (outputs to docs/ directory)\nquarto preview - Start local development server with live reload\nquarto render &lt;file.qmd&gt; - Render a specific document\nquarto check - Verify Quarto installation and project setup\n\n\n\nContent Management\n\nCreate new ML content in ML/ directory\nCreate new algorithm content in Algorithm/ directory\nUpdate navigation by editing _quarto.yml navbar section\nAdd new content to respective index.qmd files for discoverability"
  },
  {
    "objectID": "CLAUDE.html#project-structure",
    "href": "CLAUDE.html#project-structure",
    "title": "",
    "section": "Project Structure",
    "text": "Project Structure\n‚îú‚îÄ‚îÄ _quarto.yml          # Main configuration file\n‚îú‚îÄ‚îÄ docs/                # Generated output (GitHub Pages source)\n‚îú‚îÄ‚îÄ index.qmd            # Homepage\n‚îú‚îÄ‚îÄ about.qmd            # About page\n‚îú‚îÄ‚îÄ ML/                  # Machine Learning content\n‚îÇ   ‚îú‚îÄ‚îÄ index.qmd        # ML topics overview\n‚îÇ   ‚îú‚îÄ‚îÄ *.qmd            # ML articles\n‚îÇ   ‚îî‚îÄ‚îÄ *.ipynb          # Jupyter notebooks\n‚îú‚îÄ‚îÄ Algorithm/           # Algorithm content\n‚îÇ   ‚îú‚îÄ‚îÄ index.qmd        # Algorithm topics overview\n‚îÇ   ‚îî‚îÄ‚îÄ *.qmd            # Algorithm articles\n‚îú‚îÄ‚îÄ imgs/                # Image assets\n‚îú‚îÄ‚îÄ media/               # Media files\n‚îî‚îÄ‚îÄ styles.css           # Custom CSS styles"
  },
  {
    "objectID": "CLAUDE.html#content-organization",
    "href": "CLAUDE.html#content-organization",
    "title": "",
    "section": "Content Organization",
    "text": "Content Organization\nThe site uses a hierarchical navigation structure defined in _quarto.yml: - Two main sections: ‚ÄúML‚Äù and ‚ÄúAlgorithm‚Äù - Each section has an index page that serves as a directory - Content is categorized by topic (e.g., ‚ÄúNumPy Fundamentals‚Äù, ‚ÄúClustering Algorithms‚Äù)\n\nAdding New Content\n\nCreate the content file in the appropriate directory (ML/ or Math/ or Algorithm/)\nAdd to list page: Update the corresponding list page (e.g., ML/deep-learning-book.qmd, Math/MIT18.06/lectures.qmd)\nUpdate homepage automatically: Run ./update-counts.sh to update section counts on homepage\nAdd navigation entry to _quarto.yml if it should appear in the navbar dropdown\nUse consistent frontmatter with title field\nSet publication date: Always use the current date from the system for the date field in frontmatter\n\nGet current date with: date +\"%Y-%m-%d\" (format: YYYY-MM-DD)\nExample: date: \"2025-10-26\"\n\nImportant: After adding new navbar items, run quarto render (full site render) to update the navbar on ALL existing pages. Individual file renders only update that specific page.\n\n\n\nMaintaining the Homepage\nThe homepage (index.qmd) shows the latest 4 items from each section with a count badge.\nCRITICAL: When adding new content, you MUST:\n\nAdd the new item to the appropriate list page:\n\nDeep Learning: ML/deep-learning-book.qmd\nMIT 18.06SC: Math/MIT18.06/lectures.qmd\nMIT 18.065: Math/MIT18.065/lectures.qmd\n\nUpdate the homepage manually by editing index.qmd:\n\nReplace the oldest item in the ‚ÄúLatest 4‚Äù with the new item\nKeep the 4 most recent items visible\nOrder: newest first (top), oldest last (bottom)\n\nUpdate section counts automatically:\n./update-counts.sh\nThis script automatically counts items in list pages and updates the count badges in index.qmd.\nRender and verify:\nquarto render index.qmd\n\nExample workflow when adding Chapter 9.8:\n# 1. Create the new content file\nvim ML/chapter-9-8.qmd\n\n# 2. Add to list page\nvim ML/deep-learning-book.qmd  # Add Chapter 9.8 entry\n\n# 3. Update homepage\nvim index.qmd  # Replace Chapter 9.4 with 9.8, keep 9.7, 9.6, and 9.5\n\n# 4. Update counts automatically\n./update-counts.sh\n\n# 5. Render\nquarto render index.qmd\nWarning: The homepage will NOT automatically update when you add new content. You must manually update index.qmd to show the latest 4 items."
  },
  {
    "objectID": "CLAUDE.html#configuration-notes",
    "href": "CLAUDE.html#configuration-notes",
    "title": "",
    "section": "Configuration Notes",
    "text": "Configuration Notes\n\nOutput directory is set to docs/ for GitHub Pages compatibility\nTheme: Cosmo with custom branding\nAll pages include table of contents (toc: true)\nSite uses custom CSS from styles.css\nJupyter notebooks are supported alongside Quarto markdown"
  },
  {
    "objectID": "CLAUDE.html#github-pages-deployment",
    "href": "CLAUDE.html#github-pages-deployment",
    "title": "",
    "section": "GitHub Pages Deployment",
    "text": "GitHub Pages Deployment\nThe site is automatically deployed from the docs/ directory. After rendering, commit and push the docs/ folder to trigger GitHub Pages rebuild. - Author is Chao Ma - GitHub Pages URL: https://ickma2311.github.io/\n\nPre-Push Checklist (CRITICAL)\nALWAYS verify locally before pushing to prevent broken images on production:\n\nRun full render: quarto render (not individual file renders)\nCRITICAL: Restore ALL deleted images after full render\nFull site renders delete images from multiple locations. You MUST restore them:\n# 1. Restore *_files/ directories (code-generated matplotlib/plotly figures)\ncp -r ML/*_files docs/ML/ 2&gt;/dev/null\ncp -r Math/*_files docs/Math/ 2&gt;/dev/null\ncp -r Algorithm/*_files docs/Algorithm/ 2&gt;/dev/null\n\n# 2. Restore static images in ML/ and Math/\ncp ML/*.png docs/ML/ 2&gt;/dev/null\ncp Math/MIT18.06/*.png docs/Math/MIT18.06/ 2&gt;/dev/null\n\n# 3. Restore media/ directory images (referenced with ../media/image.png)\nmkdir -p docs/media\ncp media/*.png docs/media/ 2&gt;/dev/null\n\n# 4. Restore imgs/ directory images (referenced with ../imgs/image.png)\nmkdir -p docs/imgs\ncp imgs/*.png docs/imgs/ 2&gt;/dev/null\n\n# 5. Move any HTML files that failed to move\nfind ML -maxdepth 1 -name \"*.html\" -exec mv {} docs/ML/ \\; 2&gt;/dev/null\nfind Math/MIT18.06 -maxdepth 1 -name \"*.html\" -exec mv {} docs/Math/MIT18.06/ \\; 2&gt;/dev/null\nfind Algorithm -maxdepth 1 -name \"*.html\" -exec mv {} docs/Algorithm/ \\; 2&gt;/dev/null\n\n# 6. Move index files\nmv Algorithm/index.html docs/Algorithm/ 2&gt;/dev/null\nmv Math/index.html docs/Math/ 2&gt;/dev/null\nmv index-backup.html docs/ 2&gt;/dev/null\nCheck git status: git status - verify all image files are staged\n\nLook for docs/**/*_files/figure-html/*.png files (code-generated)\nLook for docs/media/*.png files (media directory)\nLook for docs/imgs/*.png files (imgs directory)\nLook for docs/ML/*.png and docs/Math/MIT18.06/*.png files (static images)\n\nLocal preview: Open docs/ HTML files in browser to verify images load\n\nCheck pages with Jupyter notebooks (e.g., mit1806-lecture1-geometry.html)\nCheck pages with media references (e.g., dropout.html)\nVerify matplotlib/plotly figures appear correctly\n\nCommit ALL generated files: Don‚Äôt commit .html without their images\nOnly then push: git push\n\nWhy this matters: GitHub Pages serves from the docs/ directory. Quarto‚Äôs full render deletes images from docs/ but keeps them in source directories. If images aren‚Äôt copied back to docs/, the HTML will reference missing files, causing broken images on production even though they work locally.\nImage locations that get deleted: - docs/**/*_files/ - Code-generated figures from Python/matplotlib - docs/media/ - Shared media referenced with ../media/ - docs/imgs/ - Shared images referenced with ../imgs/ - docs/ML/*.png - Static chapter images - docs/Math/MIT18.06/*.png - Static lecture images"
  },
  {
    "objectID": "CLAUDE.html#linkedin-post-guidelines",
    "href": "CLAUDE.html#linkedin-post-guidelines",
    "title": "",
    "section": "LinkedIn Post Guidelines",
    "text": "LinkedIn Post Guidelines\n\nEmoji Usage\nWhen drafting LinkedIn posts for blog content, use these emojis: - Deep Learning topics: ‚àá (delta/nabla symbol) - represents gradients and optimization - Linear Algebra topics: üìê (triangle/ruler) - represents geometric and matrix concepts\n\n\nWriting Process\n\nIdentify the key insight: Focus on the main conceptual connection or ‚Äúaha moment‚Äù from the blog post\nUse ‚Äúconnecting the dots‚Äù tone: Emphasize how concepts link together (e.g., ‚Äúhow linear algebra connects to machine learning‚Äù)\nStructure (Knowledge Card Format):\n\nStart with emoji and chapter reference (e.g., ‚Äú‚àá Deep Learning Book (Chapter 8.1)‚Äù or ‚Äúüìê MIT 18.06SC Linear Algebra (Lecture 19)‚Äù)\nClear statement or equation (e.g., ‚ÄúLearning ‚â† Optimization‚Äù)\n2-4 bullet points (üîπ) with key insights\nPhilosophical closing line (üí°)\nLink to full blog post (üìñ)\nSource attribution at the end (e.g., ‚ÄúMy notes on Deep Learning (Ian Goodfellow) Chapter X.X‚Äù or ‚ÄúMy notes on MIT 18.06SC Linear Algebra - Lecture XX‚Äù)\n\nKeep it concise: Aim for clarity over comprehensiveness - use knowledge card format for quick, digestible insights\nCourse naming:\n\nAlways use ‚ÄúMIT 18.06SC‚Äù (not just ‚ÄúMIT 18.06‚Äù) for linear algebra posts\nUse full course titles to maintain consistency\n\nInclude relevant hashtags: #MachineLearning #LinearAlgebra #DeepLearning"
  }
]